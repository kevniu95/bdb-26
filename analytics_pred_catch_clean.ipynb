{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ece4cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.cluster import KMeans\n",
    "from multiprocessing import Pool as MultiprocessingPool, cpu_count\n",
    "\n",
    "from src.kinematics import calculate_speed_and_direction\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cbbc19b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIG\n",
    "# ============================================================================\n",
    "\n",
    "class Config:\n",
    "    DATA_DIR = Path(\"./data\")\n",
    "    OUTPUT_DIR = Path(\"./outputs\")\n",
    "    OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "    \n",
    "    SEED = 44\n",
    "    N_FOLDS = 5\n",
    "    BATCH_SIZE = 256\n",
    "    EPOCHS = 60\n",
    "    PATIENCE = 30\n",
    "    LEARNING_RATE = 1e-4\n",
    "    \n",
    "    WINDOW_SIZE = 10\n",
    "    HIDDEN_DIM = 128\n",
    "    MAX_FUTURE_HORIZON = 94\n",
    "    \n",
    "    FIELD_X_MIN, FIELD_X_MAX = 0.0, 120.0\n",
    "    FIELD_Y_MIN, FIELD_Y_MAX = 0.0, 53.3\n",
    "    \n",
    "    K_NEIGH = 6\n",
    "    RADIUS = 30.0\n",
    "    TAU = 8.0\n",
    "    N_ROUTE_CLUSTERS = 7\n",
    "    \n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(Config.SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6162db51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/4] Loading data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m train_input_files = [config.DATA_DIR / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtrain/input_2023_w\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m19\u001b[39m)]\n\u001b[32m      6\u001b[39m train_output_files = [config.DATA_DIR / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtrain/output_2023_w\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m19\u001b[39m)]\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m train_input = pd.concat([\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m train_input_files \u001b[38;5;28;01mif\u001b[39;00m f.exists()])\n\u001b[32m      8\u001b[39m train_output = pd.concat([pd.read_csv(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m train_output_files \u001b[38;5;28;01mif\u001b[39;00m f.exists()])\n\u001b[32m      9\u001b[39m supplementary_data = pd.read_csv(config.DATA_DIR / \u001b[33m\"\u001b[39m\u001b[33msupplementary_data.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2053\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:334\u001b[39m, in \u001b[36mgetstate\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "config\n",
    "\n",
    "print(\"\\n[1/4] Loading data...\")\n",
    "train_input_files = [config.DATA_DIR / f\"train/input_2023_w{w:02d}.csv\" for w in range(1, 19)]\n",
    "train_output_files = [config.DATA_DIR / f\"train/output_2023_w{w:02d}.csv\" for w in range(1, 19)]\n",
    "train_input = pd.concat([pd.read_csv(f) for f in train_input_files if f.exists()])\n",
    "train_output = pd.concat([pd.read_csv(f) for f in train_output_files if f.exists()])\n",
    "supplementary_data = pd.read_csv(config.DATA_DIR / \"supplementary_data.csv\")\n",
    "\n",
    "print(f\"‚úì Train input: {train_input.shape}, Train output: {train_output.shape}\")\n",
    "print(f\"‚úì Train output: {train_output.shape}, unique plays: {train_output[['game_id','play_id']].drop_duplicates().shape[0]}\")\n",
    "print(f\"‚úì Supplementary data: {supplementary_data.shape}\")\n",
    "\n",
    "traj_output = pd.read_csv('local_submission.csv')\n",
    "traj_output = traj_output[['game_id', 'play_id', 'nfl_id', 'frame_id', 'pred_x', 'pred_y']]\n",
    "traj_output.rename(columns={'pred_x': 'x', 'pred_y': 'y'}, inplace=True)\n",
    "\n",
    "train_output.sort_values(by=['game_id', 'play_id', 'nfl_id', 'frame_id'], inplace=True)\n",
    "traj_output.sort_values(by=['game_id', 'play_id', 'nfl_id', 'frame_id'], inplace=True)\n",
    "\n",
    "print(f\"‚úì Projected trajectory output: {traj_output.shape}, unique plays: {traj_output[['game_id','play_id']].drop_duplicates().shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc173424",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     62\u001b[39m after_pass_frames_real[\u001b[33m'\u001b[39m\u001b[33munique_play_id\u001b[39m\u001b[33m'\u001b[39m] = after_pass_frames_real[\u001b[33m'\u001b[39m\u001b[33mgame_id\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m) + \u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m + after_pass_frames_real[\u001b[33m'\u001b[39m\u001b[33mplay_id\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m     63\u001b[39m train_output = after_pass_frames_real.copy()\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m after_pass_frames_proj = \u001b[43mattach_and_prepare_play_level_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraj_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupplementary_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m after_pass_frames_proj[\u001b[33m'\u001b[39m\u001b[33munique_play_id\u001b[39m\u001b[33m'\u001b[39m] = after_pass_frames_proj[\u001b[33m'\u001b[39m\u001b[33mgame_id\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m) + \u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m + after_pass_frames_proj[\u001b[33m'\u001b[39m\u001b[33mplay_id\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m     67\u001b[39m traj_output = after_pass_frames_proj\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mattach_and_prepare_play_level_features\u001b[39m\u001b[34m(input_df, output_df, supplementary_df)\u001b[39m\n\u001b[32m     37\u001b[39m play_results = prepare_completions(supplementary_df)\n\u001b[32m     39\u001b[39m output_df = calculate_speed_and_direction(output_df)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m input_df = \u001b[43madd_qb_and_ball_angle_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m player_level_keys = [\u001b[33m\"\u001b[39m\u001b[33mgame_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mplay_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnfl_id\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     43\u001b[39m play_features = [\u001b[33m\"\u001b[39m\u001b[33mplayer_height\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mplayer_weight\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mplayer_side\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mplayer_role\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     44\u001b[39m              \u001b[33m\"\u001b[39m\u001b[33mplayer_position\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     45\u001b[39m              \u001b[33m\"\u001b[39m\u001b[33mplay_direction\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mabsolute_yardline_number\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     46\u001b[39m              \u001b[33m\"\u001b[39m\u001b[33mball_land_x\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mball_land_y\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnum_frames_output\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     47\u001b[39m              \u001b[33m\"\u001b[39m\u001b[33mball_angle_deg\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mqb_to_ball_distance\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mball_speed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     48\u001b[39m             ]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36madd_qb_and_ball_angle_features\u001b[39m\u001b[34m(input_df)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_qb_and_ball_angle_features\u001b[39m(input_df: pd.DataFrame) -> pd.DataFrame:\n\u001b[32m      7\u001b[39m     qb_at_throw = (\n\u001b[32m      8\u001b[39m         input_df[input_df[\u001b[33m'\u001b[39m\u001b[33mplayer_role\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mPasser\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      9\u001b[39m         .sort_values([\u001b[33m'\u001b[39m\u001b[33mgame_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mplay_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mframe_id\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m         .reset_index()\n\u001b[32m     14\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     input_df = \u001b[43minput_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqb_at_throw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgame_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mplay_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mleft\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     dx = input_df[\u001b[33m'\u001b[39m\u001b[33mball_land_x\u001b[39m\u001b[33m'\u001b[39m] - input_df[\u001b[33m'\u001b[39m\u001b[33mqb_x\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     18\u001b[39m     dy = input_df[\u001b[33m'\u001b[39m\u001b[33mball_land_y\u001b[39m\u001b[33m'\u001b[39m] - input_df[\u001b[33m'\u001b[39m\u001b[33mqb_y\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/pandas/core/frame.py:10859\u001b[39m, in \u001b[36mDataFrame.merge\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10840\u001b[39m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m  10841\u001b[39m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents=\u001b[32m2\u001b[39m)\n\u001b[32m  10842\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmerge\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m  10855\u001b[39m     validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10856\u001b[39m ) -> DataFrame:\n\u001b[32m  10857\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmerge\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m> \u001b[39m\u001b[32m10859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  10860\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m  10861\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10862\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10863\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10864\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10865\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10866\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10867\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10868\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10869\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10870\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10871\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10873\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/pandas/core/reshape/merge.py:184\u001b[39m, in \u001b[36mmerge\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    170\u001b[39m     op = _MergeOperation(\n\u001b[32m    171\u001b[39m         left_df,\n\u001b[32m    172\u001b[39m         right_df,\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m         validate=validate,\n\u001b[32m    183\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/pandas/core/reshape/merge.py:888\u001b[39m, in \u001b[36m_MergeOperation.get_result\u001b[39m\u001b[34m(self, copy)\u001b[39m\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m.left, \u001b[38;5;28mself\u001b[39m.right = \u001b[38;5;28mself\u001b[39m._indicator_pre_merge(\u001b[38;5;28mself\u001b[39m.left, \u001b[38;5;28mself\u001b[39m.right)\n\u001b[32m    886\u001b[39m join_index, left_indexer, right_indexer = \u001b[38;5;28mself\u001b[39m._get_join_info()\n\u001b[32m--> \u001b[39m\u001b[32m888\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reindex_and_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    891\u001b[39m result = result.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[38;5;28mself\u001b[39m._merge_type)\n\u001b[32m    893\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.indicator:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/pandas/core/reshape/merge.py:879\u001b[39m, in \u001b[36m_MergeOperation._reindex_and_concat\u001b[39m\u001b[34m(self, join_index, left_indexer, right_indexer, copy)\u001b[39m\n\u001b[32m    877\u001b[39m left.columns = llabels\n\u001b[32m    878\u001b[39m right.columns = rlabels\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m result = \u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/pandas/core/reshape/concat.py:395\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    382\u001b[39m op = _Concatenator(\n\u001b[32m    383\u001b[39m     objs,\n\u001b[32m    384\u001b[39m     axis=axis,\n\u001b[32m   (...)\u001b[39m\u001b[32m    392\u001b[39m     sort=sort,\n\u001b[32m    393\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/pandas/core/reshape/concat.py:684\u001b[39m, in \u001b[36m_Concatenator.get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    680\u001b[39m             indexers[ax] = obj_labels.get_indexer(new_labels)\n\u001b[32m    682\u001b[39m     mgrs_indexers.append((obj._mgr, indexers))\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m new_data = \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[32m    688\u001b[39m     new_data._consolidate_inplace()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/pandas/core/internals/concat.py:131\u001b[39m, in \u001b[36mconcatenate_managers\u001b[39m\u001b[34m(mgrs_indexers, axes, concat_axis, copy)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# Assertions disabled for performance\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# for tup in mgrs_indexers:\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m#    # caller is responsible for ensuring this\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m#    indexers = tup[1]\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m#    assert concat_axis not in indexers\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m concat_axis == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     mgrs = \u001b[43m_maybe_reindex_columns_na_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneeds_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mgrs[\u001b[32m0\u001b[39m].concat_horizontal(mgrs, axes)\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mgrs_indexers) > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mgrs_indexers[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m].nblocks > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/pandas/core/internals/concat.py:230\u001b[39m, in \u001b[36m_maybe_reindex_columns_na_proxy\u001b[39m\u001b[34m(axes, mgrs_indexers, needs_copy)\u001b[39m\n\u001b[32m    220\u001b[39m         mgr = mgr.reindex_indexer(\n\u001b[32m    221\u001b[39m             axes[i],\n\u001b[32m    222\u001b[39m             indexers[i],\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m             use_na_proxy=\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# only relevant for i==0\u001b[39;00m\n\u001b[32m    228\u001b[39m         )\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m needs_copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexers:\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m         mgr = \u001b[43mmgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m     new_mgrs.append(mgr)\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_mgrs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/pandas/core/internals/managers.py:623\u001b[39m, in \u001b[36mBaseBlockManager.copy\u001b[39m\u001b[34m(self, deep)\u001b[39m\n\u001b[32m    620\u001b[39m         res._blklocs = \u001b[38;5;28mself\u001b[39m._blklocs.copy()\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m     \u001b[43mres\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/pandas/core/internals/managers.py:1810\u001b[39m, in \u001b[36mBlockManager._consolidate_inplace\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1808\u001b[39m \u001b[38;5;28mself\u001b[39m._is_consolidated = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1809\u001b[39m \u001b[38;5;28mself\u001b[39m._known_consolidated = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1810\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_rebuild_blknos_and_blklocs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/internals.pyx:755\u001b[39m, in \u001b[36mpandas._libs.internals.BlockManager._rebuild_blknos_and_blklocs\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/pandas/core/internals/base.py:82\u001b[39m, in \u001b[36mDataManager.shape\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mndim\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.axes)\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mshape\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Shape:\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ax) \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.axes)\n\u001b[32m     86\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_set_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def prepare_completions(suppl_df: pd.DataFrame) -> pd.DataFrame:\n",
    "  play_results = suppl_df[['game_id','play_id','pass_result']].drop_duplicates()\n",
    "  play_results.loc[play_results['pass_result'] == 'IN', 'pass_result'] = 'I'\n",
    "  return play_results\n",
    "\n",
    "def add_qb_and_ball_angle_features(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    qb_at_throw = (\n",
    "        input_df[input_df['player_role'] == 'Passer']\n",
    "        .sort_values(['game_id', 'play_id', 'frame_id'])\n",
    "        .groupby(['game_id', 'play_id'])\n",
    "        .last()[['x', 'y']]\n",
    "        .rename(columns={'x': 'qb_x', 'y': 'qb_y'})\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    input_df = input_df.merge(qb_at_throw, on=['game_id', 'play_id'], how='left')\n",
    "    dx = input_df['ball_land_x'] - input_df['qb_x']\n",
    "    dy = input_df['ball_land_y'] - input_df['qb_y']\n",
    "    ball_angle_rad = np.arctan2(dx, dy)\n",
    "    input_df['ball_angle_deg'] = np.degrees(ball_angle_rad) % 360\n",
    "    \n",
    "    input_df['qb_to_ball_distance'] = np.sqrt(dx**2 + dy**2)\n",
    "    input_df['ball_speed'] = input_df['qb_to_ball_distance'] / (input_df['num_frames_output'] / 10)\n",
    "    return input_df\n",
    "\n",
    "def attach_and_prepare_play_level_features(input_df: pd.DataFrame,\n",
    "                                           output_df:pd.DataFrame,\n",
    "                                           supplementary_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Attaches play-level features from input_df and supplementary_df onto output_df\n",
    "\n",
    "    Args:\n",
    "        input_df (pd.DataFrame): Input DataFrame containing pre-throw tracking data\n",
    "        output_df (pd.DataFrame): Output DataFrame containing post-throw tracking data\n",
    "        supplementary_df (pd.DataFrame): Supplementary DataFrame containing supplementary play-level information\n",
    "    \"\"\"\n",
    "    play_results = prepare_completions(supplementary_df)\n",
    "    \n",
    "    output_df = calculate_speed_and_direction(output_df)\n",
    "    input_df = add_qb_and_ball_angle_features(input_df)\n",
    "\n",
    "    player_level_keys = [\"game_id\", \"play_id\", \"nfl_id\"]\n",
    "    play_features = [\"player_height\", \"player_weight\",\"player_side\",\"player_role\",\n",
    "                 \"player_position\",\n",
    "                 \"play_direction\", \"absolute_yardline_number\",\n",
    "                 \"ball_land_x\",\"ball_land_y\", \"num_frames_output\",\n",
    "                 \"ball_angle_deg\", \"qb_to_ball_distance\", \"ball_speed\"\n",
    "                ]\n",
    "\n",
    "    input = input_df[player_level_keys + play_features].drop_duplicates()\n",
    "\n",
    "    output_df = output_df.merge(input, on=player_level_keys, how='inner')\n",
    "    output_df = output_df.merge(play_results, on=['game_id','play_id'], how='left', indicator= True)\n",
    "    assert all(output_df['_merge'] == 'both')\n",
    "    output_df = output_df.dropna(subset=['qb_to_ball_distance'])\n",
    "    output_df = output_df.drop(columns=['_merge'])\n",
    "\n",
    "    return output_df\n",
    "\n",
    "\n",
    "after_pass_frames_real = attach_and_prepare_play_level_features(train_input, train_output, supplementary_data)\n",
    "after_pass_frames_real['unique_play_id'] = after_pass_frames_real['game_id'].astype(str) + '_' + after_pass_frames_real['play_id'].astype(str)\n",
    "train_output = after_pass_frames_real.copy()\n",
    "\n",
    "after_pass_frames_proj = attach_and_prepare_play_level_features(train_input, traj_output, supplementary_data)\n",
    "after_pass_frames_proj['unique_play_id'] = after_pass_frames_proj['game_id'].astype(str) + '_' + after_pass_frames_proj['play_id'].astype(str)\n",
    "traj_output = after_pass_frames_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ae0520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GEOMETRIC BASELINE - THE BREAKTHROUGH\n",
    "# ============================================================================\n",
    "\n",
    "def compute_geometric_endpoint(df):\n",
    "    \"\"\"\n",
    "    Compute where each player SHOULD end up based on geometry.\n",
    "    This is the deterministic part - no learning needed.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Time to play end\n",
    "    if 'num_frames_output' in df.columns:\n",
    "        t_total = df['num_frames_output'] / 10.0\n",
    "    else:\n",
    "        t_total = 3.0\n",
    "    \n",
    "    df['time_to_endpoint'] = t_total\n",
    "    \n",
    "    # Initialize with momentum (default rule)\n",
    "    df['geo_endpoint_x'] = df['x'] + df['velocity_x'] * t_total\n",
    "    df['geo_endpoint_y'] = df['y'] + df['velocity_y'] * t_total\n",
    "    \n",
    "    # Rule 1: Targeted Receivers converge to ball\n",
    "    if 'ball_land_x' in df.columns:\n",
    "        receiver_mask = df['player_role'] == 'Targeted Receiver'\n",
    "        df.loc[receiver_mask, 'geo_endpoint_x'] = df.loc[receiver_mask, 'ball_land_x']\n",
    "        df.loc[receiver_mask, 'geo_endpoint_y'] = df.loc[receiver_mask, 'ball_land_y']\n",
    "        \n",
    "        # Rule 2: Defenders mirror receivers (maintain offset)\n",
    "        defender_mask = df['player_role'] == 'Defensive Coverage'\n",
    "        has_mirror = df.get('mirror_offset_x', 0).notna() & (df.get('mirror_wr_dist', 50) < 15)\n",
    "        coverage_mask = defender_mask & has_mirror\n",
    "        \n",
    "        df.loc[coverage_mask, 'geo_endpoint_x'] = (\n",
    "            df.loc[coverage_mask, 'ball_land_x'] + \n",
    "            df.loc[coverage_mask, 'mirror_offset_x'].fillna(0)\n",
    "        )\n",
    "        df.loc[coverage_mask, 'geo_endpoint_y'] = (\n",
    "            df.loc[coverage_mask, 'ball_land_y'] + \n",
    "            df.loc[coverage_mask, 'mirror_offset_y'].fillna(0)\n",
    "        )\n",
    "    \n",
    "    # Clip to field\n",
    "    df['geo_endpoint_x'] = df['geo_endpoint_x'].clip(Config.FIELD_X_MIN, Config.FIELD_X_MAX)\n",
    "    df['geo_endpoint_y'] = df['geo_endpoint_y'].clip(Config.FIELD_Y_MIN, Config.FIELD_Y_MAX)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_geometric_features(df):\n",
    "    \"\"\"Add features that describe the geometric solution\"\"\"\n",
    "    df = compute_geometric_endpoint(df)\n",
    "    \n",
    "    # Vector to geometric endpoint\n",
    "    df['geo_vector_x'] = df['geo_endpoint_x'] - df['x']\n",
    "    df['geo_vector_y'] = df['geo_endpoint_y'] - df['y']\n",
    "    df['geo_distance'] = np.sqrt(df['geo_vector_x']**2 + df['geo_vector_y']**2)\n",
    "    \n",
    "    # Required velocity to reach geometric endpoint\n",
    "    t = df['time_to_endpoint'] + 0.1\n",
    "    df['geo_required_vx'] = df['geo_vector_x'] / t\n",
    "    df['geo_required_vy'] = df['geo_vector_y'] / t\n",
    "    \n",
    "    # Current velocity vs required\n",
    "    df['geo_velocity_error_x'] = df['geo_required_vx'] - df['velocity_x']\n",
    "    df['geo_velocity_error_y'] = df['geo_required_vy'] - df['velocity_y']\n",
    "    df['geo_velocity_error'] = np.sqrt(\n",
    "        df['geo_velocity_error_x']**2 + df['geo_velocity_error_y']**2\n",
    "    )\n",
    "    \n",
    "    # Required constant acceleration (a = 2*Œîx/t¬≤)\n",
    "    t_sq = t * t\n",
    "    df['geo_required_ax'] = 2 * df['geo_vector_x'] / t_sq\n",
    "    df['geo_required_ay'] = 2 * df['geo_vector_y'] / t_sq\n",
    "    df['geo_required_ax'] = df['geo_required_ax'].clip(-10, 10)\n",
    "    df['geo_required_ay'] = df['geo_required_ay'].clip(-10, 10)\n",
    "    \n",
    "    # Alignment with geometric path\n",
    "    velocity_mag = np.sqrt(df['velocity_x']**2 + df['velocity_y']**2)\n",
    "    geo_unit_x = df['geo_vector_x'] / (df['geo_distance'] + 0.1)\n",
    "    geo_unit_y = df['geo_vector_y'] / (df['geo_distance'] + 0.1)\n",
    "    df['geo_alignment'] = (\n",
    "        df['velocity_x'] * geo_unit_x + df['velocity_y'] * geo_unit_y\n",
    "    ) / (velocity_mag + 0.1)\n",
    "    \n",
    "    # Role-specific geometric quality\n",
    "    df['geo_receiver_urgency'] = df['is_receiver'] * df['geo_distance'] / (t + 0.1)\n",
    "    df['geo_defender_coupling'] = df['is_coverage'] * (1.0 / (df.get('mirror_wr_dist', 50) + 1.0))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1cf131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_velocity(speed, direction_deg):\n",
    "    theta = np.deg2rad(direction_deg)\n",
    "    return speed * np.sin(theta), speed * np.cos(theta)\n",
    "\n",
    "def height_to_feet(height_str):\n",
    "    try:\n",
    "        ft, inches = map(int, str(height_str).split('-'))\n",
    "        return ft + inches/12\n",
    "    except:\n",
    "        return 6.0\n",
    "\n",
    "def get_opponent_features(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Enhanced opponent interaction with MIRROR WR tracking\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for (gid, pid), group in tqdm(input_df.groupby(['game_id', 'play_id']), \n",
    "                                   desc=\"üèà Opponents\", leave=False):\n",
    "        last = group.sort_values('frame_id').groupby('nfl_id').last()\n",
    "        \n",
    "        if len(last) < 2:\n",
    "            for nid in last.index:\n",
    "                  features.append({\n",
    "                      'game_id': gid, 'play_id': pid, 'nfl_id': nid,\n",
    "                      'nearest_opp_dist': 50.0, 'closing_speed': 0.0,\n",
    "                      'num_nearby_opp_3': 0, 'num_nearby_opp_5': 0,\n",
    "                      'mirror_wr_vx': 0.0, 'mirror_wr_vy': 0.0,\n",
    "                      'mirror_offset_x': 0.0, 'mirror_offset_y': 0.0,\n",
    "                      'mirror_wr_dist': 50.0,\n",
    "                  })\n",
    "            continue\n",
    "            \n",
    "        positions = last[['x', 'y']].values\n",
    "        sides = last['player_side'].values\n",
    "        speeds = last['s'].values\n",
    "        directions = last['dir'].values\n",
    "        roles = last['player_role'].values\n",
    "        \n",
    "        receiver_mask = np.isin(roles, ['Targeted Receiver', 'Other Route Runner'])\n",
    "        \n",
    "        for i, (nid, side, role) in enumerate(zip(last.index, sides, roles)):\n",
    "            opp_mask = sides != side\n",
    "            \n",
    "            feat = {\n",
    "                'game_id': gid, 'play_id': pid, 'nfl_id': nid,\n",
    "                'nearest_opp_dist': 50.0, 'closing_speed': 0.0,\n",
    "                'num_nearby_opp_3': 0, 'num_nearby_opp_5': 0,\n",
    "                'mirror_wr_vx': 0.0, 'mirror_wr_vy': 0.0,\n",
    "                'mirror_offset_x': 0.0, 'mirror_offset_y': 0.0,\n",
    "                'mirror_wr_dist': 50.0,\n",
    "            }\n",
    "            \n",
    "            if not opp_mask.any():\n",
    "                features.append(feat)\n",
    "                continue\n",
    "            \n",
    "            opp_positions = positions[opp_mask]\n",
    "            distances = np.sqrt(((positions[i] - opp_positions)**2).sum(axis=1))\n",
    "            \n",
    "            if len(distances) == 0:\n",
    "                features.append(feat)\n",
    "                continue\n",
    "                \n",
    "            nearest_idx = distances.argmin()\n",
    "            feat['nearest_opp_dist'] = distances[nearest_idx]\n",
    "            feat['num_nearby_opp_3'] = (distances < 3.0).sum()\n",
    "            feat['num_nearby_opp_5'] = (distances < 5.0).sum()\n",
    "            \n",
    "            my_vx, my_vy = get_velocity(speeds[i], directions[i])\n",
    "            opp_speeds = speeds[opp_mask]\n",
    "            opp_dirs = directions[opp_mask]\n",
    "            opp_vx, opp_vy = get_velocity(opp_speeds[nearest_idx], opp_dirs[nearest_idx])\n",
    "            \n",
    "            rel_vx = my_vx - opp_vx\n",
    "            rel_vy = my_vy - opp_vy\n",
    "            to_me = positions[i] - opp_positions[nearest_idx]\n",
    "            to_me_norm = to_me / (np.linalg.norm(to_me) + 0.1)\n",
    "            feat['closing_speed'] = -(rel_vx * to_me_norm[0] + rel_vy * to_me_norm[1])\n",
    "            \n",
    "            if role == 'Defensive Coverage' and receiver_mask.any():\n",
    "                rec_positions = positions[receiver_mask]\n",
    "                rec_distances = np.sqrt(((positions[i] - rec_positions)**2).sum(axis=1))\n",
    "                \n",
    "                if len(rec_distances) > 0:\n",
    "                    closest_rec_idx = rec_distances.argmin()\n",
    "                    rec_indices = np.where(receiver_mask)[0]\n",
    "                    actual_rec_idx = rec_indices[closest_rec_idx]\n",
    "                    \n",
    "                    rec_vx, rec_vy = get_velocity(speeds[actual_rec_idx], directions[actual_rec_idx])\n",
    "                    \n",
    "                    feat['mirror_wr_vx'] = rec_vx\n",
    "                    feat['mirror_wr_vy'] = rec_vy\n",
    "                    feat['mirror_wr_dist'] = rec_distances[closest_rec_idx]\n",
    "                    feat['mirror_offset_x'] = positions[i][0] - rec_positions[closest_rec_idx][0]\n",
    "                    feat['mirror_offset_y'] = positions[i][1] - rec_positions[closest_rec_idx][1]\n",
    "            \n",
    "            features.append(feat)\n",
    "    \n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "def compute_neighbor_embeddings(input_df, k_neigh=Config.K_NEIGH, \n",
    "                                radius=Config.RADIUS, tau=Config.TAU, print_logs=True):\n",
    "    \"\"\"GNN-lite embeddings\"\"\"\n",
    "    if print_logs:\n",
    "        print(\"üï∏Ô∏è  GNN embeddings...\")\n",
    "    \n",
    "    cols_needed = [\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\", \"x\", \"y\", \n",
    "                   \"velocity_x\", \"velocity_y\", \"player_side\"]\n",
    "    src = input_df[cols_needed].copy()\n",
    "    \n",
    "    last = (src.sort_values([\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"])\n",
    "               .groupby([\"game_id\", \"play_id\", \"nfl_id\"], as_index=False)\n",
    "               .tail(1)\n",
    "               .rename(columns={\"frame_id\": \"last_frame_id\"})\n",
    "               .reset_index(drop=True))\n",
    "    \n",
    "    all_players = last[[\"game_id\", \"play_id\", \"nfl_id\"]].copy()\n",
    "\n",
    "    tmp = last.merge(\n",
    "        src.rename(columns={\n",
    "            \"frame_id\": \"nb_frame_id\", \"nfl_id\": \"nfl_id_nb\",\n",
    "            \"x\": \"x_nb\", \"y\": \"y_nb\", \n",
    "            \"velocity_x\": \"vx_nb\", \"velocity_y\": \"vy_nb\", \n",
    "            \"player_side\": \"player_side_nb\"\n",
    "        }),\n",
    "        left_on=[\"game_id\", \"play_id\", \"last_frame_id\"],\n",
    "        right_on=[\"game_id\", \"play_id\", \"nb_frame_id\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    tmp = tmp[tmp[\"nfl_id_nb\"] != tmp[\"nfl_id\"]]\n",
    "    tmp[\"dx\"] = tmp[\"x_nb\"] - tmp[\"x\"]\n",
    "    tmp[\"dy\"] = tmp[\"y_nb\"] - tmp[\"y\"]\n",
    "    tmp[\"dvx\"] = tmp[\"vx_nb\"] - tmp[\"velocity_x\"]\n",
    "    tmp[\"dvy\"] = tmp[\"vy_nb\"] - tmp[\"velocity_y\"]\n",
    "    tmp[\"dist\"] = np.sqrt(tmp[\"dx\"]**2 + tmp[\"dy\"]**2)\n",
    "    \n",
    "    tmp = tmp[np.isfinite(tmp[\"dist\"]) & (tmp[\"dist\"] > 1e-6)]\n",
    "    if radius is not None:\n",
    "        tmp = tmp[tmp[\"dist\"] <= radius]\n",
    "    \n",
    "    tmp[\"is_ally\"] = (tmp[\"player_side_nb\"] == tmp[\"player_side\"]).astype(np.float32)\n",
    "    \n",
    "    keys = [\"game_id\", \"play_id\", \"nfl_id\"]\n",
    "    tmp[\"rnk\"] = tmp.groupby(keys)[\"dist\"].rank(method=\"first\")\n",
    "    if k_neigh is not None:\n",
    "        tmp = tmp[tmp[\"rnk\"] <= float(k_neigh)]\n",
    "    \n",
    "    tmp[\"w\"] = np.exp(-tmp[\"dist\"] / float(tau))\n",
    "    sum_w = tmp.groupby(keys)[\"w\"].transform(\"sum\")\n",
    "    tmp[\"wn\"] = np.where(sum_w > 0, tmp[\"w\"] / sum_w, 0.0)\n",
    "    \n",
    "    tmp[\"wn_ally\"] = tmp[\"wn\"] * tmp[\"is_ally\"]\n",
    "    tmp[\"wn_opp\"] = tmp[\"wn\"] * (1.0 - tmp[\"is_ally\"])\n",
    "    \n",
    "    for col in [\"dx\", \"dy\", \"dvx\", \"dvy\"]:\n",
    "        tmp[f\"{col}_ally_w\"] = tmp[col] * tmp[\"wn_ally\"]\n",
    "        tmp[f\"{col}_opp_w\"] = tmp[col] * tmp[\"wn_opp\"]\n",
    "    \n",
    "    tmp[\"dist_ally\"] = np.where(tmp[\"is_ally\"] > 0.5, tmp[\"dist\"], np.nan)\n",
    "    tmp[\"dist_opp\"] = np.where(tmp[\"is_ally\"] < 0.5, tmp[\"dist\"], np.nan)\n",
    "    \n",
    "    ag = tmp.groupby(keys).agg(\n",
    "        gnn_ally_dx_mean=(\"dx_ally_w\", \"sum\"),\n",
    "        gnn_ally_dy_mean=(\"dy_ally_w\", \"sum\"),\n",
    "        gnn_ally_dvx_mean=(\"dvx_ally_w\", \"sum\"),\n",
    "        gnn_ally_dvy_mean=(\"dvy_ally_w\", \"sum\"),\n",
    "        gnn_opp_dx_mean=(\"dx_opp_w\", \"sum\"),\n",
    "        gnn_opp_dy_mean=(\"dy_opp_w\", \"sum\"),\n",
    "        gnn_opp_dvx_mean=(\"dvx_opp_w\", \"sum\"),\n",
    "        gnn_opp_dvy_mean=(\"dvy_opp_w\", \"sum\"),\n",
    "        gnn_ally_cnt=(\"is_ally\", \"sum\"),\n",
    "        gnn_opp_cnt=(\"is_ally\", lambda s: float(len(s) - s.sum())),\n",
    "        gnn_ally_dmin=(\"dist_ally\", \"min\"),\n",
    "        gnn_ally_dmean=(\"dist_ally\", \"mean\"),\n",
    "        gnn_opp_dmin=(\"dist_opp\", \"min\"),\n",
    "        gnn_opp_dmean=(\"dist_opp\", \"mean\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    ag = all_players.merge(ag, on=keys, how=\"left\")\n",
    "\n",
    "    \n",
    "    near = tmp.loc[tmp[\"rnk\"] <= 3, keys + [\"rnk\", \"dist\"]].copy()\n",
    "    if len(near) > 0:\n",
    "        near[\"rnk\"] = near[\"rnk\"].astype(int)\n",
    "        dwide = near.pivot_table(index=keys, columns=\"rnk\", values=\"dist\", aggfunc=\"first\")\n",
    "        dwide = dwide.rename(columns={1: \"gnn_d1\", 2: \"gnn_d2\", 3: \"gnn_d3\"}).reset_index()\n",
    "        ag = ag.merge(dwide, on=keys, how=\"left\")\n",
    "    \n",
    "    for c in [\"gnn_ally_dx_mean\", \"gnn_ally_dy_mean\", \"gnn_ally_dvx_mean\", \"gnn_ally_dvy_mean\",\n",
    "              \"gnn_opp_dx_mean\", \"gnn_opp_dy_mean\", \"gnn_opp_dvx_mean\", \"gnn_opp_dvy_mean\"]:\n",
    "        ag[c] = ag[c].fillna(0.0)\n",
    "    for c in [\"gnn_ally_cnt\", \"gnn_opp_cnt\"]:\n",
    "        ag[c] = ag[c].fillna(0.0)\n",
    "    for c in [\"gnn_ally_dmin\", \"gnn_opp_dmin\", \"gnn_ally_dmean\", \"gnn_opp_dmean\", \n",
    "              \"gnn_d1\", \"gnn_d2\", \"gnn_d3\"]:\n",
    "        if c in ag.columns:\n",
    "            ag[c] = ag[c].fillna(radius if radius is not None else 30.0)\n",
    "        else:\n",
    "            # Create missing columns with default values\n",
    "            ag[c] = radius if radius is not None else 30.0\n",
    "  \n",
    "    return ag\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b673a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences_geometric(input_df, \n",
    "                                output_df=None, \n",
    "                                test_template=None, \n",
    "                                is_training=True, \n",
    "                                window_size=5,\n",
    "                                print_logs=True\n",
    "                                # route_kmeans=None, \n",
    "                                # route_scaler=None\n",
    "                                ):\n",
    "    \"\"\"\n",
    "    YOUR 154 features + 13 geometric features = 167 total\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "        If Training:\n",
    "\n",
    "        If Test:\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    if print_logs:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"PREPARING GEOMETRIC SEQUENCES\")\n",
    "        print(f\"{'='*80}\")\n",
    "    \n",
    "    input_df = input_df.copy()\n",
    "    input_df = input_df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n",
    "    \n",
    "    if print_logs:\n",
    "        print(\"Step 1: Base features...\")\n",
    "    \n",
    "    input_df['player_height_feet'] = input_df['player_height'].apply(height_to_feet)\n",
    "    height_parts = input_df['player_height'].str.split('-', expand=True)\n",
    "    input_df['height_inches'] = height_parts[0].astype(float) * 12 + height_parts[1].astype(float)\n",
    "    input_df['bmi'] = (input_df['player_weight'] / (input_df['height_inches']**2)) * 703\n",
    "    \n",
    "    dir_rad = np.deg2rad(input_df['dir'].fillna(0))\n",
    "    input_df['velocity_x'] = input_df['s'] * np.sin(dir_rad)\n",
    "    input_df['velocity_y'] = input_df['s'] * np.cos(dir_rad)\n",
    "    # input_df['acceleration_x'] = input_df['a'] * np.cos(dir_rad)\n",
    "    # input_df['acceleration_y'] = input_df['a'] * np.sin(dir_rad)\n",
    "    \n",
    "    input_df['speed_squared'] = input_df['s'] ** 2\n",
    "    # input_df['accel_magnitude'] = np.sqrt(input_df['acceleration_x']**2 + input_df['acceleration_y']**2)\n",
    "    input_df['momentum_x'] = input_df['velocity_x'] * input_df['player_weight']\n",
    "    input_df['momentum_y'] = input_df['velocity_y'] * input_df['player_weight']\n",
    "    input_df['kinetic_energy'] = 0.5 * input_df['player_weight'] * input_df['speed_squared']\n",
    "    \n",
    "    # input_df['orientation_diff'] = np.abs(input_df['o'] - input_df['dir'])\n",
    "    # input_df['orientation_diff'] = np.minimum(input_df['orientation_diff'], 360 - input_df['orientation_diff'])\n",
    "    \n",
    "    input_df['is_offense'] = (input_df['player_side'] == 'Offense').astype(int)\n",
    "    input_df['is_defense'] = (input_df['player_side'] == 'Defense').astype(int)\n",
    "    input_df['is_receiver'] = (input_df['player_role'] == 'Targeted Receiver').astype(int)\n",
    "    input_df['is_coverage'] = (input_df['player_role'] == 'Defensive Coverage').astype(int)\n",
    "    input_df['is_passer'] = (input_df['player_role'] == 'Passer').astype(int)\n",
    "    input_df['role_targeted_receiver'] = input_df['is_receiver']\n",
    "    input_df['role_defensive_coverage'] = input_df['is_coverage']\n",
    "    input_df['role_passer'] = input_df['is_passer']\n",
    "    input_df['side_offense'] = input_df['is_offense']\n",
    "    \n",
    "    if 'ball_land_x' in input_df.columns:\n",
    "        ball_dx = input_df['ball_land_x'] - input_df['x']\n",
    "        ball_dy = input_df['ball_land_y'] - input_df['y']\n",
    "        input_df['distance_to_ball'] = np.sqrt(ball_dx**2 + ball_dy**2)\n",
    "        input_df['dist_to_ball'] = input_df['distance_to_ball']\n",
    "        input_df['dist_squared'] = input_df['distance_to_ball'] ** 2\n",
    "        input_df['angle_to_ball'] = np.arctan2(ball_dy, ball_dx)\n",
    "        input_df['ball_direction_x'] = ball_dx / (input_df['distance_to_ball'] + 1e-6)\n",
    "        input_df['ball_direction_y'] = ball_dy / (input_df['distance_to_ball'] + 1e-6)\n",
    "        input_df['closing_speed_ball'] = (\n",
    "            input_df['velocity_x'] * input_df['ball_direction_x'] +\n",
    "            input_df['velocity_y'] * input_df['ball_direction_y']\n",
    "        )\n",
    "        input_df['velocity_toward_ball'] = (\n",
    "            input_df['velocity_x'] * np.cos(input_df['angle_to_ball']) + \n",
    "            input_df['velocity_y'] * np.sin(input_df['angle_to_ball'])\n",
    "        )\n",
    "        input_df['velocity_alignment'] = np.cos(input_df['angle_to_ball'] - dir_rad)\n",
    "        # input_df['angle_diff'] = np.abs(input_df['o'] - np.degrees(input_df['angle_to_ball']))\n",
    "        # input_df['angle_diff'] = np.minimum(input_df['angle_diff'], 360 - input_df['angle_diff'])\n",
    "    \n",
    "    if print_logs:\n",
    "        print(\"Step 2: Advanced features...\")\n",
    "    \n",
    "    opp_features = get_opponent_features(input_df)\n",
    "    input_df = input_df.merge(opp_features, on=['game_id', 'play_id', 'nfl_id'], how='left')\n",
    "    \n",
    "    # if is_training:\n",
    "    #     route_features, route_kmeans, route_scaler = extract_route_patterns(input_df)\n",
    "    # else:\n",
    "    #     route_features = extract_route_patterns(input_df, route_kmeans, route_scaler, fit=False)\n",
    "    # input_df = input_df.merge(route_features, on=['game_id', 'play_id', 'nfl_id'], how='left')\n",
    "    \n",
    "    gnn_features = compute_neighbor_embeddings(input_df, print_logs = print_logs)\n",
    "    input_df = input_df.merge(gnn_features, on=['game_id', 'play_id', 'nfl_id'], how='left')\n",
    "    \n",
    "    if 'nearest_opp_dist' in input_df.columns:\n",
    "        input_df['pressure'] = 1 / np.maximum(input_df['nearest_opp_dist'], 0.5)\n",
    "        input_df['under_pressure'] = (input_df['nearest_opp_dist'] < 3).astype(int)\n",
    "        input_df['pressure_x_speed'] = input_df['pressure'] * input_df['s']\n",
    "    \n",
    "    if 'mirror_wr_vx' in input_df.columns:\n",
    "        s_safe = np.maximum(input_df['s'], 0.1)\n",
    "        input_df['mirror_similarity'] = (\n",
    "            input_df['velocity_x'] * input_df['mirror_wr_vx'] + \n",
    "            input_df['velocity_y'] * input_df['mirror_wr_vy']\n",
    "        ) / s_safe\n",
    "        input_df['mirror_offset_dist'] = np.sqrt(\n",
    "            input_df['mirror_offset_x']**2 + input_df['mirror_offset_y']**2\n",
    "        )\n",
    "        input_df['mirror_alignment'] = input_df['mirror_similarity'] * input_df['role_defensive_coverage']\n",
    "    \n",
    "    if print_logs:\n",
    "        print(\"Step 3: Temporal features...\")\n",
    "    \n",
    "    gcols = ['game_id', 'play_id', 'nfl_id']\n",
    "    \n",
    "    # TODO: Add more lags/windows as needed?\n",
    "    for lag in [1, 2, 3, 4, 5]:\n",
    "        # for col in ['x', 'y', 'velocity_x', 'velocity_y', 's', 'a']:\n",
    "        for col in ['x', 'y', 'velocity_x', 'velocity_y', 's']:\n",
    "            if col in input_df.columns:\n",
    "                input_df[f'{col}_lag{lag}'] = input_df.groupby(gcols)[col].shift(lag)\n",
    "    \n",
    "    for window in [3, 5]:\n",
    "        for col in ['x', 'y', 'velocity_x', 'velocity_y', 's']:\n",
    "            if col in input_df.columns:\n",
    "                input_df[f'{col}_rolling_mean_{window}'] = (\n",
    "                    input_df.groupby(gcols)[col]\n",
    "                      .rolling(window, min_periods=1).mean()\n",
    "                      .reset_index(level=[0,1,2], drop=True)\n",
    "                )\n",
    "                input_df[f'{col}_rolling_std_{window}'] = (\n",
    "                    input_df.groupby(gcols)[col]\n",
    "                      .rolling(window, min_periods=1).std()\n",
    "                      .reset_index(level=[0,1,2], drop=True)\n",
    "                )\n",
    "    \n",
    "    for col in ['velocity_x', 'velocity_y']:\n",
    "        if col in input_df.columns:\n",
    "            input_df[f'{col}_delta'] = input_df.groupby(gcols)[col].diff()\n",
    "    \n",
    "    input_df['velocity_x_ema'] = input_df.groupby(gcols)['velocity_x'].transform(\n",
    "        lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n",
    "    )\n",
    "    input_df['velocity_y_ema'] = input_df.groupby(gcols)['velocity_y'].transform(\n",
    "        lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n",
    "    )\n",
    "    input_df['speed_ema'] = input_df.groupby(gcols)['s'].transform(\n",
    "        lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n",
    "    )\n",
    "    \n",
    "    if print_logs:\n",
    "        print(\"Step 4: Time features...\")\n",
    "    \n",
    "    if 'num_frames_output' in input_df.columns:\n",
    "        max_frames = input_df['num_frames_output']\n",
    "        \n",
    "        input_df['max_play_duration'] = max_frames / 10.0\n",
    "        input_df['frame_time'] = input_df['frame_id'] / 10.0\n",
    "        input_df['progress_ratio'] = input_df['frame_id'] / np.maximum(max_frames, 1)\n",
    "        input_df['time_remaining'] = (max_frames - input_df['frame_id']) / 10.0\n",
    "        input_df['frames_remaining'] = max_frames - input_df['frame_id']\n",
    "        \n",
    "        input_df['expected_x_at_ball'] = input_df['x'] + input_df['velocity_x'] * input_df['frame_time']\n",
    "        input_df['expected_y_at_ball'] = input_df['y'] + input_df['velocity_y'] * input_df['frame_time']\n",
    "        \n",
    "        if 'ball_land_x' in input_df.columns:\n",
    "            input_df['error_from_ball_x'] = input_df['expected_x_at_ball'] - input_df['ball_land_x']\n",
    "            input_df['error_from_ball_y'] = input_df['expected_y_at_ball'] - input_df['ball_land_y']\n",
    "            input_df['error_from_ball'] = np.sqrt(\n",
    "                input_df['error_from_ball_x']**2 + input_df['error_from_ball_y']**2\n",
    "            )\n",
    "            \n",
    "            input_df['weighted_dist_by_time'] = input_df['dist_to_ball'] / (input_df['frame_time'] + 0.1)\n",
    "            input_df['dist_scaled_by_progress'] = input_df['dist_to_ball'] * (1 - input_df['progress_ratio'])\n",
    "        \n",
    "        input_df['time_squared'] = input_df['frame_time'] ** 2\n",
    "        input_df['velocity_x_progress'] = input_df['velocity_x'] * input_df['progress_ratio']\n",
    "        input_df['velocity_y_progress'] = input_df['velocity_y'] * input_df['progress_ratio']\n",
    "        input_df['speed_scaled_by_time_left'] = input_df['s'] * input_df['time_remaining']\n",
    "        \n",
    "        input_df['actual_play_length'] = max_frames\n",
    "        input_df['length_ratio'] = max_frames / 30.0\n",
    "    \n",
    "    # üéØ THE BREAKTHROUGH: Add geometric features\n",
    "    if print_logs:\n",
    "        print(\"Step 5: üéØ Geometric endpoint features...\")\n",
    "    input_df = add_geometric_features(input_df)\n",
    "    \n",
    "    if print_logs:\n",
    "        print(\"Step 6: Building feature list...\")\n",
    "    \n",
    "    # Your 154 proven features\n",
    "    feature_cols = [\n",
    "        'x', 'y', 's', \n",
    "        # 'a', 'o', \n",
    "        'dir', 'frame_id', 'ball_land_x', 'ball_land_y',\n",
    "        'player_height_feet', 'player_weight', 'height_inches', 'bmi',\n",
    "        'velocity_x', 'velocity_y', \n",
    "        # 'acceleration_x', 'acceleration_y',\n",
    "        'momentum_x', 'momentum_y', 'kinetic_energy',\n",
    "        'speed_squared', 'accel_magnitude', \n",
    "        # 'orientation_diff',\n",
    "        'is_offense', 'is_defense', 'is_receiver', 'is_coverage', 'is_passer',\n",
    "        'role_targeted_receiver', 'role_defensive_coverage', 'role_passer', 'side_offense',\n",
    "        'distance_to_ball', 'dist_to_ball', 'dist_squared', 'angle_to_ball', \n",
    "        'ball_direction_x', 'ball_direction_y', 'closing_speed_ball',\n",
    "        'velocity_toward_ball', 'velocity_alignment', \n",
    "        # 'angle_diff',\n",
    "        'nearest_opp_dist', 'closing_speed', 'num_nearby_opp_3', 'num_nearby_opp_5',\n",
    "        'mirror_wr_vx', 'mirror_wr_vy', 'mirror_offset_x', 'mirror_offset_y',\n",
    "        'pressure', 'under_pressure', 'pressure_x_speed', \n",
    "        'mirror_similarity', 'mirror_offset_dist', 'mirror_alignment',\n",
    "        # 'route_pattern', 'traj_straightness', 'traj_max_turn', 'traj_mean_turn',\n",
    "        # 'traj_depth', 'traj_width', 'speed_mean', 'speed_change',\n",
    "        'gnn_ally_dx_mean', 'gnn_ally_dy_mean', 'gnn_ally_dvx_mean', 'gnn_ally_dvy_mean',\n",
    "        'gnn_opp_dx_mean', 'gnn_opp_dy_mean', 'gnn_opp_dvx_mean', 'gnn_opp_dvy_mean',\n",
    "        'gnn_ally_cnt', 'gnn_opp_cnt',\n",
    "        'gnn_ally_dmin', 'gnn_ally_dmean', 'gnn_opp_dmin', 'gnn_opp_dmean',\n",
    "        'gnn_d1', 'gnn_d2', 'gnn_d3',\n",
    "        'ball_angle_deg', 'qb_to_ball_distance', 'ball_speed',\n",
    "    ]\n",
    "    \n",
    "    for lag in [1, 2, 3, 4, 5]:\n",
    "        # for col in ['x', 'y', 'velocity_x', 'velocity_y', 's', 'a']:\n",
    "        for col in ['x', 'y', 'velocity_x', 'velocity_y', 's']:\n",
    "            feature_cols.append(f'{col}_lag{lag}')\n",
    "    \n",
    "    for window in [3, 5]:\n",
    "        for col in ['x', 'y', 'velocity_x', 'velocity_y', 's']:\n",
    "            feature_cols.append(f'{col}_rolling_mean_{window}')\n",
    "            feature_cols.append(f'{col}_rolling_std_{window}')\n",
    "    \n",
    "    feature_cols.extend(['velocity_x_delta', 'velocity_y_delta'])\n",
    "    feature_cols.extend(['velocity_x_ema', 'velocity_y_ema', 'speed_ema'])\n",
    "    \n",
    "    feature_cols.extend([\n",
    "        'max_play_duration', 'frame_time', 'progress_ratio', 'time_remaining', 'frames_remaining',\n",
    "        'expected_x_at_ball', 'expected_y_at_ball', \n",
    "        'error_from_ball_x', 'error_from_ball_y', 'error_from_ball',\n",
    "        'time_squared', 'weighted_dist_by_time', \n",
    "        'velocity_x_progress', 'velocity_y_progress', 'dist_scaled_by_progress',\n",
    "        'speed_scaled_by_time_left', 'actual_play_length', 'length_ratio',\n",
    "    ])\n",
    "    \n",
    "    # üéØ Add 13 geometric features\n",
    "    feature_cols.extend([\n",
    "        'geo_endpoint_x', 'geo_endpoint_y',\n",
    "        'geo_vector_x', 'geo_vector_y', 'geo_distance',\n",
    "        'geo_required_vx', 'geo_required_vy',\n",
    "        'geo_velocity_error_x', 'geo_velocity_error_y', 'geo_velocity_error',\n",
    "        'geo_required_ax', 'geo_required_ay',\n",
    "        'geo_alignment',\n",
    "    ])\n",
    "    \n",
    "    feature_cols = [c for c in feature_cols if c in input_df.columns]\n",
    "    if print_logs:\n",
    "        print(f\"‚úì Using {len(feature_cols)} features ({len(feature_cols) - 13} proven + 13 geometric)\")\n",
    "    \n",
    "        print(\"Step 7: Creating sequences...\")\n",
    "    \n",
    "    target_rows = input_df.copy() # Instantiate before we mess with input_df\n",
    "    target_groups = target_rows[['game_id', 'play_id']].drop_duplicates()\n",
    "\n",
    "    sequences, targets_catch, sequence_ids = [], [], []\n",
    "\n",
    "    for _, row in tqdm(target_groups.iterrows(), total=len(target_groups), desc=\"Creating sequences\", disable = not print_logs):\n",
    "        # key = (row['game_id'], row['play_id'], row['nfl_id']) \n",
    "        key = (row['game_id'], row['play_id'])\n",
    "        \n",
    "        try:\n",
    "            group_df = input_df[(input_df['game_id']==row['game_id']) &\n",
    "                                 (input_df['play_id']==row['play_id'])]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        \n",
    "        group_df = group_df[group_df['player_role']=='Targeted Receiver']\n",
    "        input_window = group_df.tail(window_size)\n",
    "        \n",
    "        if len(input_window) < window_size:\n",
    "            if is_training:\n",
    "                continue\n",
    "            pad_len = window_size - len(input_window)\n",
    "            pad_df = pd.DataFrame(np.nan, index=range(pad_len), columns=input_window.columns)\n",
    "            input_window = pd.concat([pad_df, input_window], ignore_index=True)\n",
    "        \n",
    "        input_window = input_window.fillna(group_df.mean(numeric_only=True))\n",
    "        seq = input_window[feature_cols].values\n",
    "        \n",
    "        if np.isnan(seq).any():\n",
    "            if is_training:\n",
    "                # Print the columns that have NaNs\n",
    "                nan_cols = input_window[feature_cols].columns[input_window[feature_cols].isna().any()].tolist()\n",
    "                print(f\"Columns with NaNs: {nan_cols}\")\n",
    "                print()\n",
    "                continue\n",
    "            seq = np.nan_to_num(seq, nan=0.0)\n",
    "        \n",
    "        sequences.append(seq)\n",
    "        \n",
    "        # Store geometric endpoint for this player\n",
    "        geo_x = input_window.iloc[-1]['geo_endpoint_x']\n",
    "        geo_y = input_window.iloc[-1]['geo_endpoint_y']\n",
    "        \n",
    "        if is_training:\n",
    "            out_grp = output_df[\n",
    "                (output_df['game_id']==group_df.iloc[0]['game_id']) &\n",
    "                (output_df['play_id']==group_df.iloc[0]['play_id']) &\n",
    "                (output_df['nfl_id']==group_df.iloc[0]['nfl_id'])\n",
    "            ].sort_values('frame_id')\n",
    "\n",
    "            was_catch = out_grp['pass_result'].values[0] == 'C'\n",
    "            targets_catch.append(1 if was_catch else 0)\n",
    "            \n",
    "        sequence_ids.append({\n",
    "            'game_id': key[0],\n",
    "            'play_id': key[1],\n",
    "            'frame_id': input_window.iloc[-1]['frame_id']\n",
    "        })\n",
    "\n",
    "    if print_logs:\n",
    "        print(f\"‚úì Created {len(sequences)} sequences\")\n",
    "    \n",
    "    if is_training:\n",
    "        return (sequences, \n",
    "                targets_catch,\n",
    "                # targets_dx,\n",
    "                # targets_dy, \n",
    "                # targets_frame_ids, \n",
    "                sequence_ids, \n",
    "                # geo_endpoints_x, \n",
    "                # geo_endpoints_y, \n",
    "                # route_kmeans, \n",
    "                # route_scaler,\n",
    "                feature_cols)\n",
    "    return sequences, sequence_ids#, geo_endpoints_x, geo_endpoints_y\n",
    "    # return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2cd992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODEL ARCHITECTURE (YOUR PROVEN GRU + ATTENTION)\n",
    "# ============================================================================\n",
    "class JointSeqModel(nn.Module):\n",
    "    \"\"\"Your proven architecture - unchanged\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_dim, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
    "        self.pool_ln = nn.LayerNorm(128)\n",
    "        self.pool_attn = nn.MultiheadAttention(128, num_heads=4, batch_first=True)\n",
    "        self.pool_query = nn.Parameter(torch.randn(1, 1, 128))\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(128, 256), \n",
    "            nn.GELU(), \n",
    "            nn.Dropout(0.2), \n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h, _ = self.gru(x)\n",
    "        B = h.size(0)\n",
    "        q = self.pool_query.expand(B, -1, -1)\n",
    "        ctx, _ = self.pool_attn(q, self.pool_ln(h), self.pool_ln(h))\n",
    "        out = self.head(ctx.squeeze(1))\n",
    "        return out.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d40d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "# ============================================================================\n",
    "# TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "def prepare_targets(batch_dx, batch_dy, max_h):\n",
    "    tensors_x, tensors_y, masks = [], [], []\n",
    "    \n",
    "    for dx, dy in zip(batch_dx, batch_dy):\n",
    "        L = len(dx)\n",
    "        padded_x = np.pad(dx, (0, max_h - L), constant_values=0).astype(np.float32)\n",
    "        padded_y = np.pad(dy, (0, max_h - L), constant_values=0).astype(np.float32)\n",
    "        mask = np.zeros(max_h, dtype=np.float32)\n",
    "        mask[:L] = 1.0\n",
    "        \n",
    "        tensors_x.append(torch.tensor(padded_x))\n",
    "        tensors_y.append(torch.tensor(padded_y))\n",
    "        masks.append(torch.tensor(mask))\n",
    "    \n",
    "    targets = torch.stack([torch.stack(tensors_x), torch.stack(tensors_y)], dim=-1)\n",
    "    return targets, torch.stack(masks)\n",
    "\n",
    "def train_model(X_train: List[np.ndarray], \n",
    "                y_train: List[int], \n",
    "                X_val: List[np.ndarray], \n",
    "                y_val: List[int], \n",
    "                input_dim: int, \n",
    "                config: Config):\n",
    "    device = config.DEVICE\n",
    "    model = JointSeqModel(input_dim).to(device)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=1e-5)\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "    \n",
    "    train_batches = []\n",
    "    for i in range(0, len(X_train), config.BATCH_SIZE):\n",
    "        end = min(i + config.BATCH_SIZE, len(X_train))\n",
    "        bx = torch.tensor(np.stack(X_train[i:end]).astype(np.float32))\n",
    "        by = torch.tensor(np.stack(y_train[i:end]).astype(np.float32))\n",
    "        train_batches.append((bx, by))\n",
    "    \n",
    "    val_batches = []\n",
    "    for i in range(0, len(X_val), config.BATCH_SIZE):\n",
    "        end = min(i + config.BATCH_SIZE, len(X_val))\n",
    "        bx = torch.tensor(np.stack(X_val[i:end]).astype(np.float32))\n",
    "        by = torch.tensor(np.stack(y_val[i:end]).astype(np.float32))\n",
    "        val_batches.append((bx, by))\n",
    "    \n",
    "    best_loss, best_state, bad = float('inf'), None, 0\n",
    "    \n",
    "    for epoch in range(1, config.EPOCHS + 1):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for bx, by in train_batches:\n",
    "            bx, by = bx.to(device), by.to(device)\n",
    "            pred = model(bx)\n",
    "            loss = criterion(pred, by)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for bx, by in val_batches:\n",
    "                bx, by = bx.to(device), by.to(device)\n",
    "                pred = model(bx)\n",
    "                val_losses.append(criterion(pred, by).item())\n",
    "                # ADD THESE 2 LINES:\n",
    "                all_preds.append(torch.sigmoid(pred).cpu().numpy())\n",
    "                all_targets.append(by.cpu().numpy())\n",
    "              \n",
    "        train_loss, val_loss = np.mean(train_losses), np.mean(val_losses)\n",
    "        # ADD THESE LINES:\n",
    "        y_pred_proba = np.concatenate(all_preds)\n",
    "        y_true = np.concatenate(all_targets)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "        \n",
    "        auc = roc_auc_score(y_true, y_pred_proba)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        \n",
    "        # scheduler.step(val_loss)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"  Epoch {epoch}: train={train_loss:.4f}, val={val_loss:.4f} | \"\n",
    "                f\"AUC={auc:.3f}, Acc={acc:.3f}, Prec={precision:.3f}, Rec={recall:.3f}, F1={f1:.3f}\")\n",
    "      \n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            train_loss_at_best = train_loss\n",
    "            auc_at_best = auc\n",
    "            accuracy_at_best = acc\n",
    "            precision_at_best = precision\n",
    "            recall_at_best = recall\n",
    "            f1_at_best = f1\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= config.PATIENCE:\n",
    "                print(f\"  Early stop at epoch {epoch}\")\n",
    "                break\n",
    "    \n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "    \n",
    "    return model, best_loss, train_loss_at_best, auc_at_best, accuracy_at_best, precision_at_best, recall_at_best, f1_at_best, y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6655dd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13135 plays for debugging/testing.\n",
      "Note this doesn't count any samples dropped from train_output during data processing\n",
      "\n",
      "================================================================================\n",
      "PREPARING GEOMETRIC SEQUENCES\n",
      "================================================================================\n",
      "Step 1: Base features...\n",
      "Step 2: Advanced features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üï∏Ô∏è  GNN embeddings...\n",
      "Step 3: Temporal features...\n",
      "Step 4: Time features...\n",
      "Step 5: üéØ Geometric endpoint features...\n",
      "Step 6: Building feature list...\n",
      "‚úì Using 150 features (137 proven + 13 geometric)\n",
      "Step 7: Creating sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating sequences: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13132/13132 [02:28<00:00, 88.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Created 13132 sequences\n",
      "\n",
      "================================================================================\n",
      "PREPARING GEOMETRIC SEQUENCES\n",
      "================================================================================\n",
      "Step 1: Base features...\n",
      "Step 2: Advanced features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üï∏Ô∏è  GNN embeddings...\n",
      "Step 3: Temporal features...\n",
      "Step 4: Time features...\n",
      "Step 5: üéØ Geometric endpoint features...\n",
      "Step 6: Building feature list...\n",
      "‚úì Using 150 features (137 proven + 13 geometric)\n",
      "Step 7: Creating sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating sequences: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13132/13132 [02:27<00:00, 88.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Created 13132 sequences\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "sample_plays = False\n",
    "number_sampled = 10\n",
    "\n",
    "min_frame_length = 7\n",
    "if min_frame_length:\n",
    "    train_input = train_input[train_input['num_frames_output'] >= min_frame_length].copy()    \n",
    "\n",
    "if sample_plays:\n",
    "    unique_plays = train_input[['game_id', 'play_id']].drop_duplicates()\n",
    "    sampled_plays = unique_plays.sample(n=number_sampled, random_state=42)\n",
    "else:\n",
    "    sampled_plays = train_input[['game_id', 'play_id']].drop_duplicates()\n",
    "\n",
    "print(f\"Using {len(sampled_plays)} plays for debugging/testing.\") \n",
    "print(\"Note this doesn't count any samples dropped from train_output during data processing\")\n",
    "@dataclass\n",
    "class TrajectoryObject:\n",
    "    input_df: pd.DataFrame\n",
    "    sequences: List[np.ndarray]\n",
    "    targets_catch: List[int]\n",
    "    sequence_ids: List[dict]\n",
    "    feature_cols: List[str]\n",
    "\n",
    "real_output_sampled = train_output.merge(sampled_plays, on=['game_id', 'play_id'], how='inner')\n",
    "real_result = prepare_sequences_geometric(real_output_sampled, output_df = real_output_sampled)\n",
    "realTrajectoryObject = TrajectoryObject(real_output_sampled, *real_result)\n",
    "\n",
    "traj_output_sampled = traj_output.merge(sampled_plays, on=['game_id', 'play_id'], how='inner')\n",
    "traj_result = prepare_sequences_geometric(traj_output_sampled, output_df = traj_output_sampled)\n",
    "projTrajectoryObject = TrajectoryObject(\n",
    "    traj_output_sampled, *traj_result\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d74283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def train_logistic_regression(X_train: List[np.ndarray], \n",
    "                              y_train: List[int], \n",
    "                              input_dim: int, \n",
    "                              config: Config,\n",
    "                              cv_folds: int = 3):\n",
    "    \"\"\"\n",
    "    Train logistic regression with cross-validation for hyperparameter tuning.\n",
    "    \n",
    "    Args:\n",
    "        X_train: List of sequences (each shape: window_size x num_features)\n",
    "        y_train: Binary labels (0/1)\n",
    "        input_dim: Number of features (used for compatibility, not directly used)\n",
    "        config: Config object\n",
    "        cv_folds: Number of CV folds for GridSearchCV (default 3)\n",
    "    \n",
    "    Returns:\n",
    "        model: Best fitted LogisticRegression model\n",
    "        best_score: Best cross-validation AUC score\n",
    "    \"\"\"\n",
    "    # Flatten sequences: (num_samples, window_size, features) -> (num_samples, window_size * features)\n",
    "    X_train_flat = np.vstack([s.flatten() for s in X_train])\n",
    "    y_train_array = np.array(y_train)\n",
    "    \n",
    "    print(f\"  Flattened shape: {X_train_flat.shape}\")\n",
    "    \n",
    "    # Define hyperparameter grid\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],  # Regularization strength\n",
    "        'penalty': ['l2'],  # L2 regularization\n",
    "        'max_iter': [2000],\n",
    "        'solver': ['lbfgs']  # Good for L2\n",
    "    }\n",
    "    \n",
    "    # Base model\n",
    "    base_model = LogisticRegression(random_state=config.SEED, class_weight='balanced')\n",
    "    \n",
    "    # Grid search with cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "        base_model,\n",
    "        param_grid,\n",
    "        cv=cv_folds,\n",
    "        scoring='roc_auc',  # Optimize for AUC\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(f\"  Running {cv_folds}-fold GridSearchCV...\")\n",
    "    grid_search.fit(X_train_flat, y_train_array)\n",
    "    \n",
    "    print(f\"  ‚úì Best params: {grid_search.best_params_}\")\n",
    "    print(f\"  ‚úì Best CV AUC: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Get best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Compute final training metrics\n",
    "    y_train_pred_proba = best_model.predict_proba(X_train_flat)[:, 1]\n",
    "    train_loss = log_loss(y_train_array, y_train_pred_proba)\n",
    "    train_auc = roc_auc_score(y_train_array, y_train_pred_proba)\n",
    "    \n",
    "    print(f\"  ‚úì Final train loss: {train_loss:.4f}, AUC: {train_auc:.4f}\")\n",
    "    \n",
    "    return best_model, grid_search.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f3de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_only(X_train: List[np.ndarray], \n",
    "                      y_train: List[int], \n",
    "                      input_dim: int, \n",
    "                      config: Config):\n",
    "    device = config.DEVICE\n",
    "    model = JointSeqModel(input_dim).to(device)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, \n",
    "        T_max=config.EPOCHS,\n",
    "        eta_min=1e-6  # Min LR at end\n",
    "    )\n",
    "    \n",
    "    train_batches = []\n",
    "    for i in range(0, len(X_train), config.BATCH_SIZE):\n",
    "        end = min(i + config.BATCH_SIZE, len(X_train))\n",
    "        bx = torch.tensor(np.stack(X_train[i:end]).astype(np.float32))\n",
    "        by = torch.tensor(np.stack(y_train[i:end]).astype(np.float32))\n",
    "        train_batches.append((bx, by))\n",
    "  \n",
    "    for epoch in range(1, config.EPOCHS + 1):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for bx, by in train_batches:\n",
    "            bx, by = bx.to(device), by.to(device)\n",
    "            pred = model(bx)\n",
    "            loss = criterion(pred, by)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())              \n",
    "        scheduler.step()\n",
    "   \n",
    "        train_loss = np.mean(train_losses)\n",
    "     \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"  Epoch {epoch}: train={train_loss:.4f}\")\n",
    "      \n",
    "        return model, train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995c82c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def predict_batch(model, X_data: List[np.ndarray], config: Config) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Predict on a list of sequences with batching for efficiency.\n",
    "    Works for any size - single play or thousands.\n",
    "    \"\"\"\n",
    "    # model.eval()\n",
    "    device = config.DEVICE\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X_data), config.BATCH_SIZE):\n",
    "            end = min(i + config.BATCH_SIZE, len(X_data))\n",
    "            batch = torch.tensor(np.stack(X_data[i:end]).astype(np.float32)).to(device)\n",
    "            \n",
    "            # Get logits and convert to probabilities\n",
    "            logits = model(batch)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            all_preds.append(probs)\n",
    "    \n",
    "    return np.concatenate(all_preds)\n",
    "\n",
    "def predict_single(model, scaler, sequence: np.ndarray, config: Config) -> float:\n",
    "    \"\"\"\n",
    "    Predict on a SINGLE sequence (for real-time inference).\n",
    "    sequence shape: (window_size, num_features)\n",
    "    \"\"\"\n",
    "    # model.eval()\n",
    "    device = config.DEVICE\n",
    "    \n",
    "    # Scale and tensorize\n",
    "    seq_scaled = scaler.transform(sequence)\n",
    "    seq_tensor = torch.tensor(seq_scaled.astype(np.float32)).unsqueeze(0).to(device)  # Add batch dim\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logit = model(seq_tensor)\n",
    "        prob = torch.sigmoid(logit).cpu().item()  # Single scalar\n",
    "    \n",
    "    return prob\n",
    "\n",
    "def compute_metrics(y_true: np.ndarray, y_pred_proba: np.ndarray, prefix: str = \"\") -> dict:\n",
    "    \"\"\"\n",
    "    Compute classification metrics.\n",
    "    \n",
    "    Args:\n",
    "        y_true: Ground truth labels (0 or 1)\n",
    "        y_pred_proba: Predicted probabilities (0 to 1)\n",
    "        prefix: Optional prefix for metric names (e.g., \"val_\", \"real_\")\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of metrics\n",
    "    \"\"\"\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    \n",
    "    metrics = {\n",
    "        f'{prefix}bce': log_loss(y_true, y_pred_proba),\n",
    "        f'{prefix}auc': roc_auc_score(y_true, y_pred_proba),\n",
    "        f'{prefix}acc': accuracy_score(y_true, y_pred),\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def print_metrics(metrics: dict, title: str = \"Metrics\"):\n",
    "    \"\"\"Pretty print metrics\"\"\"\n",
    "    print(f\"\\n{title}:\")\n",
    "    for name, value in metrics.items():\n",
    "        print(f\"  {name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e0cfe593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hybrid_trajectory(base_df: pd.DataFrame, \n",
    "                             swap_df: pd.DataFrame, \n",
    "                             game_id: int, \n",
    "                             play_id: int, \n",
    "                             swap_nfl_id: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create hybrid trajectory: all players projected EXCEPT swap_nfl_id (real).\n",
    "    \n",
    "    Args:\n",
    "        base_df: The baseline trajectory df w. trajectories of all non-swapped players\n",
    "        swap_df: The trajectory df containing swapped player's trajectory\n",
    "        game_id, play_id: Identify the play\n",
    "        swap_nfl_id: Which defender to use real trajectory for\n",
    "    \n",
    "    Returns:\n",
    "        Hybrid DataFrame ready for feature engineering\n",
    "    \"\"\"\n",
    "    # Start with projected\n",
    "    play_proj = base_df[(base_df['game_id'] == game_id) & \n",
    "                        (base_df['play_id'] == play_id)].copy()\n",
    "    \n",
    "    # Get real trajectory for ONE defender\n",
    "    defender_real = swap_df[(swap_df['game_id'] == game_id) & \n",
    "                           (swap_df['play_id'] == play_id) & \n",
    "                           (swap_df['nfl_id'] == swap_nfl_id)].copy()\n",
    "    \n",
    "    # Swap: remove projected version, add real version\n",
    "    play_hybrid = play_proj[play_proj['nfl_id'] != swap_nfl_id]\n",
    "    play_hybrid = pd.concat([play_hybrid, defender_real], ignore_index=True)\n",
    "    play_hybrid = play_hybrid.sort_values(['nfl_id', 'frame_id'])\n",
    "    \n",
    "    return play_hybrid\n",
    "\n",
    "def get_defender_impact(model: nn.Module, \n",
    "                        scaler: any, \n",
    "                        proj_df: pd.DataFrame, \n",
    "                        real_df: pd.DataFrame, \n",
    "                        game_id: int, \n",
    "                        play_id: int, \n",
    "                        config: any) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Measure each defender's impact on catch probability.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: [nfl_id, baseline_prob, real_prob, delta]\n",
    "    \"\"\"\n",
    "    # Baseline: All projected\n",
    "    play_proj = proj_df[(proj_df['game_id'] == game_id) & \n",
    "                        (proj_df['play_id'] == play_id)]\n",
    "    \n",
    "    # Get list of defenders\n",
    "    defenders = play_proj['nfl_id'].unique()\n",
    "    \n",
    "    if len(defenders) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Baseline prediction (all projected)\n",
    "    baseline_seq, _ = prepare_sequences_geometric(\n",
    "        play_proj, output_df=play_proj, is_training=False, window_size=5, print_logs = False\n",
    "    )\n",
    "    baseline_seq_sc = [scaler.transform(s) for s in baseline_seq]\n",
    "    baseline_flat = np.vstack([s.flatten() for s in baseline_seq_sc])\n",
    "    # baseline_prob = predict_batch(model, baseline_seq_sc, config)[0]\n",
    "    baseline_prob = model.predict_proba(baseline_flat)[:, 1][0]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for defender_id in defenders:\n",
    "        # print(f\"Processing for defender {defender_id}\")\n",
    "        # Create hybrid: this defender real, others projected\n",
    "        hybrid_df = create_hybrid_trajectory(\n",
    "            proj_df, real_df, game_id, play_id, defender_id\n",
    "        )\n",
    "        \n",
    "        # Re-engineer features (GNN, opponents, etc.)\n",
    "        hybrid_seq, _ = prepare_sequences_geometric(\n",
    "            hybrid_df, output_df=hybrid_df, is_training=False, window_size=5, print_logs = False\n",
    "        )\n",
    "        \n",
    "        # Predict\n",
    "        hybrid_seq_sc = [scaler.transform(s) for s in hybrid_seq]\n",
    "        hybrid_flat = np.vstack([s.flatten() for s in hybrid_seq_sc])\n",
    "        # real_prob = predict_batch(model, hybrid_seq_sc, config)[0]\n",
    "        real_prob = model.predict_proba(hybrid_flat)[:, 1][0]\n",
    "        \n",
    "        results.append({\n",
    "            'nfl_id': defender_id,\n",
    "            'player_role': play_proj[play_proj['nfl_id'] == defender_id]['player_role'].values[0],\n",
    "            'baseline_prob': baseline_prob,\n",
    "            'real_prob': real_prob,\n",
    "            'delta': real_prob - baseline_prob,  # Negative = defender suppressed catch\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def get_defender_impact_flipped(model: nn.Module, \n",
    "                        scaler: any, \n",
    "                        proj_df: pd.DataFrame, \n",
    "                        real_df: pd.DataFrame, \n",
    "                        game_id: int, \n",
    "                        play_id: int, \n",
    "                        config: any) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Measure each defender's impact on catch probability.\n",
    "\n",
    "    In this case, the baseline is all REAL, and we swap in projected for each defender.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: [nfl_id, baseline_prob, real_prob, delta]\n",
    "    \"\"\"\n",
    "    # Baseline: All projected\n",
    "    play_real = real_df[(real_df['game_id'] == game_id) & \n",
    "                        (real_df['play_id'] == play_id)]\n",
    "    \n",
    "    \n",
    "    # Get list of defenders\n",
    "    defenders = play_real['nfl_id'].unique()\n",
    "    \n",
    "    if len(defenders) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Baseline prediction (all projected)\n",
    "    real_seq, _ = prepare_sequences_geometric(\n",
    "        play_real, output_df=play_real, is_training=False, window_size=5, print_logs = False\n",
    "    )\n",
    "    real_seq_sc = [scaler.transform(s) for s in real_seq]\n",
    "    real_flat = np.vstack([s.flatten() for s in real_seq_sc])\n",
    "    # real_prob = model.predict_proba(real_flat)[:, 1][0]\n",
    "    real_prob = model.predict(real_flat)[0]  # ‚úÖ USE .predict() NOT ()\n",
    "\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for defender_id in defenders:\n",
    "        # print(f\"Processing for defender {defender_id}\")\n",
    "        # Create hybrid: this defender real, others projected\n",
    "        hybrid_df = create_hybrid_trajectory(\n",
    "            real_df, proj_df, game_id, play_id, defender_id\n",
    "        )\n",
    "        \n",
    "        # Re-engineer features (GNN, opponents, etc.)\n",
    "        hybrid_seq, _ = prepare_sequences_geometric(\n",
    "            hybrid_df, output_df=hybrid_df, is_training=False, window_size=5, print_logs = False\n",
    "        )\n",
    "        \n",
    "        # Predict\n",
    "        hybrid_seq_sc = [scaler.transform(s) for s in hybrid_seq]\n",
    "        hybrid_flat = np.vstack([s.flatten() for s in hybrid_seq_sc])\n",
    "        baseline_prob = model.predict(hybrid_flat)[0]  # ‚úÖ USE .predict() NOT ()\n",
    "        # baseline_prob = model.predict_proba(hybrid_flat)[:, 1][0]\n",
    "        # NOTE: Baseline here is the swapped projected version\n",
    "        \n",
    "        results.append({\n",
    "            'nfl_id': defender_id,\n",
    "            'player_role': play_real[play_real['nfl_id'] == defender_id]['player_role'].values[0],\n",
    "            'baseline_prob': baseline_prob,\n",
    "            'real_prob': real_prob,\n",
    "            'delta': real_prob - baseline_prob,  # Negative = defender suppressed catch\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2bcdd120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/4] Training geometric models...\n",
      "\n",
      "============================================================\n",
      "Fold 1/5\n",
      "============================================================\n",
      "  Flattened shape: (10516, 750)\n",
      "  Running 3-fold GridSearchCV...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m X_traj_sc = [scaler.transform(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m X_traj]\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# model, train_loss = train_model_only(X_all_sc, y_all, X_all[0].shape[-1], config)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m model, cv_score = \u001b[43mtrain_logistic_regression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_all_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_all\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_folds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\n\u001b[32m     33\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Predict on real trajectories\u001b[39;00m\n\u001b[32m     36\u001b[39m X_out_flat = np.vstack([s.flatten() \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m X_out_sc])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mtrain_logistic_regression\u001b[39m\u001b[34m(X_train, y_train, input_dim, config, cv_folds)\u001b[39m\n\u001b[32m     41\u001b[39m grid_search = GridSearchCV(\n\u001b[32m     42\u001b[39m     base_model,\n\u001b[32m     43\u001b[39m     param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     47\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     48\u001b[39m )\n\u001b[32m     50\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Running \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_folds\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-fold GridSearchCV...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ‚úì Best params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search.best_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ‚úì Best CV AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search.best_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"\\n[3/4] Training geometric models...\")\n",
    "sequence_ids = realTrajectoryObject.sequence_ids\n",
    "sequences = realTrajectoryObject.sequences\n",
    "\n",
    "groups = np.array([d['game_id'] for d in sequence_ids])\n",
    "gkf = GroupKFold(n_splits=config.N_FOLDS)\n",
    "\n",
    "models, scalers = [], []\n",
    "\n",
    "calibration_r2s = []  # ADD THIS BEFORE LOOP\n",
    "importance_dfs = []  # STORE IMPORTANCE DFS\n",
    "\n",
    "want_out_fold_metrics = True\n",
    "for fold, (tr, va) in enumerate(gkf.split(sequences, groups=groups), 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Fold {fold}/{config.N_FOLDS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    X_all = [sequences[i] for i in tr]; y_all = [realTrajectoryObject.targets_catch[i] for i in tr]\n",
    "    X_out = [sequences[i] for i in va]; y_out = [realTrajectoryObject.targets_catch[i] for i in va]\n",
    "    X_traj = [projTrajectoryObject.sequences[i] for i in va]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(np.vstack([s for s in X_all]))\n",
    "\n",
    "    X_all_sc = [scaler.transform(s) for s in X_all]\n",
    "    X_out_sc = [scaler.transform(s) for s in X_out]\n",
    "    X_traj_sc = [scaler.transform(s) for s in X_traj]\n",
    "\n",
    "    # model, train_loss = train_model_only(X_all_sc, y_all, X_all[0].shape[-1], config)\n",
    "    model, cv_score = train_logistic_regression(\n",
    "        X_all_sc, y_all, X_all[0].shape[-1], config, cv_folds=3\n",
    "    )\n",
    "\n",
    "    # Predict on real trajectories\n",
    "    X_out_flat = np.vstack([s.flatten() for s in X_out_sc])\n",
    "    preds_out = model.predict_proba(X_out_flat)[:, 1]\n",
    "    # preds_out = predict_batch(model, X_out_sc, config)\n",
    "    print(f\"‚úì Predicted on {len(preds_out)} validation plays\")\n",
    "    print(f\"  Mean catch prob: {preds_out.mean():.3f}, Std: {preds_out.std():.3f}\")\n",
    "    if want_out_fold_metrics:\n",
    "        # üî• EVALUATE: Real trajectories vs ground truth\n",
    "        metrics_real = compute_metrics(np.array(y_out), preds_out, prefix=\"real_\")\n",
    "        print_metrics(metrics_real, title=\"üìä Validation Metrics (Real Trajectories)\")\n",
    "\n",
    "    # Predict on projected trajectories\n",
    "    X_traj_flat = np.vstack([s.flatten() for s in X_traj_sc])\n",
    "    preds_traj = model.predict_proba(X_traj_flat)[:, 1]\n",
    "    # preds_traj = predict_batch(model, X_traj_sc, config)\n",
    "    print(f\"‚úì Predicted on {len(preds_traj)} projected trajectories\")\n",
    "\n",
    "    # Join preds_out and preds_traj into a DataFrame for comparison, with game_id and play_id\n",
    "    game_ids = [projTrajectoryObject.sequence_ids[i]['game_id'] for i in va]\n",
    "    play_ids = [projTrajectoryObject.sequence_ids[i]['play_id'] for i in va]\n",
    "    out_df = pd.DataFrame(zip(game_ids, play_ids, preds_traj, preds_out))\n",
    "    out_df.columns = ['game_id', 'play_id', 'pred_catch_prob_by_proj_traj', 'pred_catch_prob_by_real_traj']\n",
    "    # Write with appends to CSV\n",
    "    out_df.to_csv(config.OUTPUT_DIR / f'catch_probabilities_log_flip.csv', index=False, header= fold == 1, mode='w' if fold == 1 else 'a')\n",
    "\n",
    "\n",
    "    # ===================\n",
    "    # The cool part - assessing defensive player impact\n",
    "    # ===================\n",
    "    val_game_ids = [projTrajectoryObject.sequence_ids[i]['game_id'] for i in va]\n",
    "    val_play_ids = [projTrajectoryObject.sequence_ids[i]['play_id'] for i in va]\n",
    "    \n",
    "    all_impacts = []\n",
    "    \n",
    "    for num, (game_id, play_id) in enumerate(zip(val_game_ids, val_play_ids)):\n",
    "        if num % 100 == 0:\n",
    "            print(f\"Processing defender impact for game {game_id}, play {play_id} (index {num})\")\n",
    "        impact_df = get_defender_impact_flipped(\n",
    "            model, scaler, \n",
    "            projTrajectoryObject.input_df,  # Projected trajectories\n",
    "            realTrajectoryObject.input_df,   # Real trajectories\n",
    "            game_id, play_id, config\n",
    "        )\n",
    "        \n",
    "        if impact_df is not None:\n",
    "            impact_df['game_id'] = game_id\n",
    "            impact_df['play_id'] = play_id\n",
    "            impact_df['fold'] = fold\n",
    "            impact_df = impact_df[['game_id', 'play_id', 'nfl_id', 'player_role', 'baseline_prob', 'real_prob', 'delta', 'fold']]\n",
    "            all_impacts.append(impact_df)\n",
    "    \n",
    "    if all_impacts:\n",
    "        fold_impact_df = pd.concat(all_impacts, ignore_index=True)\n",
    "        # Save to CSV\n",
    "        fold_impact_df.to_csv(config.OUTPUT_DIR / f'defender_impact_log_flip.csv', index=False, header = fold == 1, mode='w' if fold == 1 else 'a')\n",
    "        # out_df.to_csv(config.OUTPUT_DIR / f'catch_probabilities.csv', index=False, header= fold == 1, mode='w' if fold == 1 else 'a')\n",
    "        print(f\"‚úì Saved defender impact for fold {fold} with {len(fold_impact_df)} records\")\n",
    "\n",
    "\n",
    "    # preds_out = model.predict(X_out_sc, config)\n",
    "    # preds_traj = model.predict(X_traj_sc, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da80e95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>play_id</th>\n",
       "      <th>nfl_id</th>\n",
       "      <th>player_role</th>\n",
       "      <th>baseline_prob</th>\n",
       "      <th>real_prob</th>\n",
       "      <th>delta</th>\n",
       "      <th>fold</th>\n",
       "      <th>pass_result</th>\n",
       "      <th>yards_gained</th>\n",
       "      <th>season</th>\n",
       "      <th>week</th>\n",
       "      <th>home_team_abbr</th>\n",
       "      <th>visitor_team_abbr</th>\n",
       "      <th>play_description</th>\n",
       "      <th>quarter</th>\n",
       "      <th>game_clock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28066</th>\n",
       "      <td>2023091701</td>\n",
       "      <td>3025</td>\n",
       "      <td>41282</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.061843</td>\n",
       "      <td>0.844657</td>\n",
       "      <td>0.782814</td>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>BUF</td>\n",
       "      <td>LV</td>\n",
       "      <td>(12:57) (Shotgun) J.Garoppolo pass incomplete ...</td>\n",
       "      <td>4</td>\n",
       "      <td>12:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38324</th>\n",
       "      <td>2023091711</td>\n",
       "      <td>1082</td>\n",
       "      <td>55928</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.123415</td>\n",
       "      <td>0.790457</td>\n",
       "      <td>0.667041</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>53</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>DEN</td>\n",
       "      <td>WAS</td>\n",
       "      <td>(13:15) (Shotgun) R.Wilson pass deep left to M...</td>\n",
       "      <td>2</td>\n",
       "      <td>13:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30835</th>\n",
       "      <td>2023101600</td>\n",
       "      <td>4288</td>\n",
       "      <td>47911</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.179383</td>\n",
       "      <td>0.796526</td>\n",
       "      <td>0.617143</td>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>LAC</td>\n",
       "      <td>DAL</td>\n",
       "      <td>(2:28) (Shotgun) D.Prescott pass incomplete de...</td>\n",
       "      <td>4</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11334</th>\n",
       "      <td>2023100805</td>\n",
       "      <td>2735</td>\n",
       "      <td>55133</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.093919</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.594607</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>NE</td>\n",
       "      <td>NO</td>\n",
       "      <td>(9:12) (Shotgun) D.Carr pass short right to R....</td>\n",
       "      <td>3</td>\n",
       "      <td>09:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29581</th>\n",
       "      <td>2023100110</td>\n",
       "      <td>2087</td>\n",
       "      <td>48097</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.081735</td>\n",
       "      <td>0.666244</td>\n",
       "      <td>0.584508</td>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>LAC</td>\n",
       "      <td>LV</td>\n",
       "      <td>(1:11) (Shotgun) A.O'Connell pass short right ...</td>\n",
       "      <td>2</td>\n",
       "      <td>01:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39829</th>\n",
       "      <td>2023100111</td>\n",
       "      <td>205</td>\n",
       "      <td>52425</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.249542</td>\n",
       "      <td>0.821715</td>\n",
       "      <td>0.572173</td>\n",
       "      <td>5</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>DAL</td>\n",
       "      <td>NE</td>\n",
       "      <td>(12:16) (No Huddle, Shotgun) D.Prescott pass i...</td>\n",
       "      <td>1</td>\n",
       "      <td>12:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20257</th>\n",
       "      <td>2023101508</td>\n",
       "      <td>2360</td>\n",
       "      <td>41233</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.224503</td>\n",
       "      <td>0.788287</td>\n",
       "      <td>0.563785</td>\n",
       "      <td>3</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>TB</td>\n",
       "      <td>DET</td>\n",
       "      <td>(7:52) (Shotgun) B.Mayfield pass incomplete sh...</td>\n",
       "      <td>3</td>\n",
       "      <td>07:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30629</th>\n",
       "      <td>2023101505</td>\n",
       "      <td>3419</td>\n",
       "      <td>39989</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.048402</td>\n",
       "      <td>0.609544</td>\n",
       "      <td>0.561142</td>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>HOU</td>\n",
       "      <td>NO</td>\n",
       "      <td>(9:40) (Shotgun) C.Stroud pass incomplete deep...</td>\n",
       "      <td>4</td>\n",
       "      <td>09:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>2023091707</td>\n",
       "      <td>1259</td>\n",
       "      <td>53506</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.326438</td>\n",
       "      <td>0.881550</td>\n",
       "      <td>0.555111</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>TEN</td>\n",
       "      <td>LAC</td>\n",
       "      <td>(8:29) (Shotgun) J.Herbert pass incomplete sho...</td>\n",
       "      <td>2</td>\n",
       "      <td>08:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>2023102201</td>\n",
       "      <td>3284</td>\n",
       "      <td>41282</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.309605</td>\n",
       "      <td>0.844710</td>\n",
       "      <td>0.535104</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>CHI</td>\n",
       "      <td>LV</td>\n",
       "      <td>(12:28) (Shotgun) B.Hoyer pass incomplete shor...</td>\n",
       "      <td>4</td>\n",
       "      <td>12:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35714</th>\n",
       "      <td>2023121010</td>\n",
       "      <td>3486</td>\n",
       "      <td>55885</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.137002</td>\n",
       "      <td>0.669851</td>\n",
       "      <td>0.532849</td>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "      <td>57</td>\n",
       "      <td>2023</td>\n",
       "      <td>14</td>\n",
       "      <td>LAC</td>\n",
       "      <td>DEN</td>\n",
       "      <td>(11:48) (Shotgun) E.Stick pass deep left to Q....</td>\n",
       "      <td>4</td>\n",
       "      <td>11:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46020</th>\n",
       "      <td>2024010712</td>\n",
       "      <td>3392</td>\n",
       "      <td>55959</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.108709</td>\n",
       "      <td>0.640311</td>\n",
       "      <td>0.531602</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>16</td>\n",
       "      <td>2023</td>\n",
       "      <td>18</td>\n",
       "      <td>ARI</td>\n",
       "      <td>SEA</td>\n",
       "      <td>(6:05) (Shotgun) K.Murray pass short right to ...</td>\n",
       "      <td>4</td>\n",
       "      <td>06:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34915</th>\n",
       "      <td>2023120700</td>\n",
       "      <td>865</td>\n",
       "      <td>44874</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.104040</td>\n",
       "      <td>0.630231</td>\n",
       "      <td>0.526191</td>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>14</td>\n",
       "      <td>PIT</td>\n",
       "      <td>NE</td>\n",
       "      <td>(2:20) (Shotgun) B.Zappe pass incomplete deep ...</td>\n",
       "      <td>1</td>\n",
       "      <td>02:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19469</th>\n",
       "      <td>2023100106</td>\n",
       "      <td>3897</td>\n",
       "      <td>43399</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.261266</td>\n",
       "      <td>0.779289</td>\n",
       "      <td>0.518023</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>IND</td>\n",
       "      <td>LA</td>\n",
       "      <td>(1:56) (Shotgun) M.Stafford pass short right t...</td>\n",
       "      <td>4</td>\n",
       "      <td>01:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13178</th>\n",
       "      <td>2023102907</td>\n",
       "      <td>3809</td>\n",
       "      <td>53074</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.023724</td>\n",
       "      <td>0.541675</td>\n",
       "      <td>0.517951</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>33</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>TEN</td>\n",
       "      <td>ATL</td>\n",
       "      <td>(7:06) (Shotgun) W.Levis pass deep left to N.W...</td>\n",
       "      <td>4</td>\n",
       "      <td>07:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41795</th>\n",
       "      <td>2023110510</td>\n",
       "      <td>4204</td>\n",
       "      <td>54553</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.233218</td>\n",
       "      <td>0.745251</td>\n",
       "      <td>0.512032</td>\n",
       "      <td>5</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>PHI</td>\n",
       "      <td>DAL</td>\n",
       "      <td>(1:22) (Shotgun) D.Prescott pass incomplete sh...</td>\n",
       "      <td>4</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19582</th>\n",
       "      <td>2023100113</td>\n",
       "      <td>1476</td>\n",
       "      <td>54475</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.013754</td>\n",
       "      <td>0.523701</td>\n",
       "      <td>0.509947</td>\n",
       "      <td>3</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>NYJ</td>\n",
       "      <td>KC</td>\n",
       "      <td>(9:19) Z.Wilson pass incomplete deep right to ...</td>\n",
       "      <td>2</td>\n",
       "      <td>09:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18788</th>\n",
       "      <td>2023091008</td>\n",
       "      <td>3254</td>\n",
       "      <td>54597</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.173099</td>\n",
       "      <td>0.680547</td>\n",
       "      <td>0.507448</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>CHI</td>\n",
       "      <td>GB</td>\n",
       "      <td>(13:34) J.Love pass short left to R.Doubs for ...</td>\n",
       "      <td>4</td>\n",
       "      <td>13:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36213</th>\n",
       "      <td>2023122405</td>\n",
       "      <td>2966</td>\n",
       "      <td>45094</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.063826</td>\n",
       "      <td>0.564930</td>\n",
       "      <td>0.501104</td>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>16</td>\n",
       "      <td>MIN</td>\n",
       "      <td>DET</td>\n",
       "      <td>(3:58) N.Mullens pass incomplete deep left to ...</td>\n",
       "      <td>3</td>\n",
       "      <td>03:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20764</th>\n",
       "      <td>2023102210</td>\n",
       "      <td>1994</td>\n",
       "      <td>43454</td>\n",
       "      <td>Targeted Receiver</td>\n",
       "      <td>0.088820</td>\n",
       "      <td>0.584106</td>\n",
       "      <td>0.495286</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>27</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>PHI</td>\n",
       "      <td>MIA</td>\n",
       "      <td>(:45) (Shotgun) T.Tagovailoa pass deep left to...</td>\n",
       "      <td>2</td>\n",
       "      <td>00:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          game_id  play_id  nfl_id        player_role  baseline_prob  \\\n",
       "28066  2023091701     3025   41282  Targeted Receiver       0.061843   \n",
       "38324  2023091711     1082   55928  Targeted Receiver       0.123415   \n",
       "30835  2023101600     4288   47911  Targeted Receiver       0.179383   \n",
       "11334  2023100805     2735   55133  Targeted Receiver       0.093919   \n",
       "29581  2023100110     2087   48097  Targeted Receiver       0.081735   \n",
       "39829  2023100111      205   52425  Targeted Receiver       0.249542   \n",
       "20257  2023101508     2360   41233  Targeted Receiver       0.224503   \n",
       "30629  2023101505     3419   39989  Targeted Receiver       0.048402   \n",
       "783    2023091707     1259   53506  Targeted Receiver       0.326438   \n",
       "3198   2023102201     3284   41282  Targeted Receiver       0.309605   \n",
       "35714  2023121010     3486   55885  Targeted Receiver       0.137002   \n",
       "46020  2024010712     3392   55959  Targeted Receiver       0.108709   \n",
       "34915  2023120700      865   44874  Targeted Receiver       0.104040   \n",
       "19469  2023100106     3897   43399  Targeted Receiver       0.261266   \n",
       "13178  2023102907     3809   53074  Targeted Receiver       0.023724   \n",
       "41795  2023110510     4204   54553  Targeted Receiver       0.233218   \n",
       "19582  2023100113     1476   54475  Targeted Receiver       0.013754   \n",
       "18788  2023091008     3254   54597  Targeted Receiver       0.173099   \n",
       "36213  2023122405     2966   45094  Targeted Receiver       0.063826   \n",
       "20764  2023102210     1994   43454  Targeted Receiver       0.088820   \n",
       "\n",
       "       real_prob     delta  fold pass_result  yards_gained  season  week  \\\n",
       "28066   0.844657  0.782814     4           I             0    2023     2   \n",
       "38324   0.790457  0.667041     5           C            53    2023     2   \n",
       "30835   0.796526  0.617143     4           I             0    2023     6   \n",
       "11334   0.688525  0.594607     2           C             3    2023     5   \n",
       "29581   0.666244  0.584508     4           C             8    2023     4   \n",
       "39829   0.821715  0.572173     5           I             0    2023     4   \n",
       "20257   0.788287  0.563785     3           I             0    2023     6   \n",
       "30629   0.609544  0.561142     4           I             0    2023     6   \n",
       "783     0.881550  0.555111     1           I             0    2023     2   \n",
       "3198    0.844710  0.535104     1           I             0    2023     7   \n",
       "35714   0.669851  0.532849     4           C            57    2023    14   \n",
       "46020   0.640311  0.531602     5           C            16    2023    18   \n",
       "34915   0.630231  0.526191     4           I             0    2023    14   \n",
       "19469   0.779289  0.518023     3           C             5    2023     4   \n",
       "13178   0.541675  0.517951     2           C            33    2023     8   \n",
       "41795   0.745251  0.512032     5           I             0    2023     9   \n",
       "19582   0.523701  0.509947     3           I             0    2023     4   \n",
       "18788   0.680547  0.507448     3           C             4    2023     1   \n",
       "36213   0.564930  0.501104     4           I             0    2023    16   \n",
       "20764   0.584106  0.495286     3           C            27    2023     7   \n",
       "\n",
       "      home_team_abbr visitor_team_abbr  \\\n",
       "28066            BUF                LV   \n",
       "38324            DEN               WAS   \n",
       "30835            LAC               DAL   \n",
       "11334             NE                NO   \n",
       "29581            LAC                LV   \n",
       "39829            DAL                NE   \n",
       "20257             TB               DET   \n",
       "30629            HOU                NO   \n",
       "783              TEN               LAC   \n",
       "3198             CHI                LV   \n",
       "35714            LAC               DEN   \n",
       "46020            ARI               SEA   \n",
       "34915            PIT                NE   \n",
       "19469            IND                LA   \n",
       "13178            TEN               ATL   \n",
       "41795            PHI               DAL   \n",
       "19582            NYJ                KC   \n",
       "18788            CHI                GB   \n",
       "36213            MIN               DET   \n",
       "20764            PHI               MIA   \n",
       "\n",
       "                                        play_description  quarter game_clock  \n",
       "28066  (12:57) (Shotgun) J.Garoppolo pass incomplete ...        4      12:57  \n",
       "38324  (13:15) (Shotgun) R.Wilson pass deep left to M...        2      13:15  \n",
       "30835  (2:28) (Shotgun) D.Prescott pass incomplete de...        4      02:28  \n",
       "11334  (9:12) (Shotgun) D.Carr pass short right to R....        3      09:12  \n",
       "29581  (1:11) (Shotgun) A.O'Connell pass short right ...        2      01:11  \n",
       "39829  (12:16) (No Huddle, Shotgun) D.Prescott pass i...        1      12:16  \n",
       "20257  (7:52) (Shotgun) B.Mayfield pass incomplete sh...        3      07:52  \n",
       "30629  (9:40) (Shotgun) C.Stroud pass incomplete deep...        4      09:40  \n",
       "783    (8:29) (Shotgun) J.Herbert pass incomplete sho...        2      08:29  \n",
       "3198   (12:28) (Shotgun) B.Hoyer pass incomplete shor...        4      12:28  \n",
       "35714  (11:48) (Shotgun) E.Stick pass deep left to Q....        4      11:48  \n",
       "46020  (6:05) (Shotgun) K.Murray pass short right to ...        4      06:05  \n",
       "34915  (2:20) (Shotgun) B.Zappe pass incomplete deep ...        1      02:20  \n",
       "19469  (1:56) (Shotgun) M.Stafford pass short right t...        4      01:56  \n",
       "13178  (7:06) (Shotgun) W.Levis pass deep left to N.W...        4      07:06  \n",
       "41795  (1:22) (Shotgun) D.Prescott pass incomplete sh...        4      01:22  \n",
       "19582  (9:19) Z.Wilson pass incomplete deep right to ...        2      09:19  \n",
       "18788  (13:34) J.Love pass short left to R.Doubs for ...        4      13:34  \n",
       "36213  (3:58) N.Mullens pass incomplete deep left to ...        3      03:58  \n",
       "20764  (:45) (Shotgun) T.Tagovailoa pass deep left to...        2      00:45  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = pd.read_csv('./outputs/defender_impact_log_wr.csv')\n",
    "# c.columns = ['game_id', 'play_id', 'nfl_id', 'baseline_prob', 'real_prob', 'delta', 'fold']\n",
    "# c.head()\n",
    "c = c.merge(supplementary_data[['game_id','play_id','pass_result', 'yards_gained', 'season','week','home_team_abbr','visitor_team_abbr','play_description', 'quarter','game_clock']],\n",
    "        on=['game_id','play_id'], how='left')\n",
    "# c[(c['game_id'] == 2023091711) & (c['play_id'] == 1082)]\n",
    "c.sort_values('delta', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6d493a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def train_lightgbm_with_tuning(X_train: List[np.ndarray], \n",
    "                                y_train: List[int],\n",
    "                                X_val: List[np.ndarray],\n",
    "                                y_val: List[int],\n",
    "                                config: Config):\n",
    "    \"\"\"\n",
    "    Train LightGBM with GridSearchCV hyperparameter optimization.\n",
    "    TODO: Add Optuna support for more advanced tuning if needed.\n",
    "    \"\"\"\n",
    "    # Flatten sequences\n",
    "    X_train_flat = np.vstack([s.flatten() for s in X_train])\n",
    "    X_val_flat = np.vstack([s.flatten() for s in X_val])\n",
    "    y_train_array = np.array(y_train)\n",
    "    y_val_array = np.array(y_val)\n",
    "    \n",
    "    print(f\"  Training: {X_train_flat.shape} | Validation: {X_val_flat.shape}\")\n",
    "    \n",
    "    param_grid = {\n",
    "            'num_leaves': [15],  # 31=conservative, 63=current, 127=aggressive\n",
    "            'learning_rate': [0.0075],  # 0.05=current, test slower/faster\n",
    "            'reg_lambda': [2.0],  # L2 penalty - you had 0, try stronger\n",
    "            \n",
    "            'n_estimators': [500],\n",
    "            'min_child_samples': [20],\n",
    "            'subsample': [0.8],\n",
    "            'colsample_bytree': [0.8],\n",
    "            'reg_alpha': [0],\n",
    "        }\n",
    "    base_model = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        metric='binary_logloss',\n",
    "        random_state=config.SEED,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        base_model, param_grid, cv=3, scoring='neg_log_loss', n_jobs=-1, verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"  ‚ö° Running GridSearchCV...\")\n",
    "    grid_search.fit(X_train_flat, y_train_array)\n",
    "    \n",
    "    print(f\"  ‚úì Best CV AUC: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"  ‚úì Best params: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Convert to LightGBM native params\n",
    "    best_params = grid_search.best_estimator_.get_params()\n",
    "    lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'seed': config.SEED,\n",
    "        **{k: best_params[k] for k in ['num_leaves', 'learning_rate', 'n_estimators', \n",
    "                                        'min_child_samples', 'subsample', 'colsample_bytree', \n",
    "                                        'reg_alpha', 'reg_lambda']}\n",
    "    }\n",
    "\n",
    "    # Train final model with early stopping\n",
    "    train_data = lgb.Dataset(X_train_flat, label=y_train_array)\n",
    "    val_data = lgb.Dataset(X_val_flat, label=y_val_array, reference=train_data)\n",
    "    \n",
    "    final_model = lgb.train(\n",
    "        lgb_params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[train_data, val_data],\n",
    "        valid_names=['train', 'valid'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=100, verbose=False),\n",
    "            lgb.log_evaluation(period=500)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    y_train_pred = final_model.predict(X_train_flat)\n",
    "    y_val_pred = final_model.predict(X_val_flat)\n",
    "    \n",
    "    train_auc = roc_auc_score(y_train_array, y_train_pred)\n",
    "    val_auc = roc_auc_score(y_val_array, y_val_pred)\n",
    "    train_bce = log_loss(y_train_array, y_train_pred)\n",
    "    val_bce = log_loss(y_val_array, y_val_pred)\n",
    "    \n",
    "    print(f\"\\n  üìä Final Metrics:\")\n",
    "    print(f\"     Train AUC: {train_auc:.4f} | BCE: {train_bce:.4f}\")\n",
    "    print(f\"     Val   AUC: {val_auc:.4f} | BCE: {val_bce:.4f}\")\n",
    "\n",
    "    if train_auc - val_auc > 0.10:\n",
    "        print(f\"  ‚ö†Ô∏è  WARNING: AUC gap = {train_auc - val_auc:.3f} (overfitting)\")\n",
    "    if train_bce < val_bce - 0.05:\n",
    "        print(f\"  ‚ö†Ô∏è  WARNING: BCE gap = {val_bce - train_bce:.3f} (poor calibration)\")\n",
    "    \n",
    "    return final_model, val_auc, val_bce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed197ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/4] Training LightGBM models...\n",
      "\n",
      "============================================================\n",
      "Fold 1/5\n",
      "============================================================\n",
      "  Training: (10516, 750) | Validation: (2616, 750)\n",
      "  ‚ö° Running GridSearchCV...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kniu91/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/kniu91/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/kniu91/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Best CV AUC: -0.4163\n",
      "  ‚úì Best params: {'colsample_bytree': 0.8, 'learning_rate': 0.0075, 'min_child_samples': 20, 'n_estimators': 500, 'num_leaves': 15, 'reg_alpha': 0, 'reg_lambda': 2.0, 'subsample': 0.8}\n",
      "[500]\ttrain's auc: 0.896607\tvalid's auc: 0.868193\n",
      "\n",
      "  üìä Final Metrics:\n",
      "     Train AUC: 0.8965 | BCE: 0.3742\n",
      "     Val   AUC: 0.8682 | BCE: 0.3975\n",
      "‚úì Predicted on 2616 validation plays (real trajectories)\n",
      "  Mean catch prob: 0.683, Std: 0.274\n",
      "\n",
      "üìä Validation Metrics (Real Trajectories):\n",
      "  real_bce: 0.3975\n",
      "  real_auc: 0.8682\n",
      "  real_acc: 0.8330\n",
      "‚úì Predicted on 2616 projected trajectories\n",
      "Processing defender impact for game 2023091000, play 185 (index 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023091003, play 2571 (index 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023091704, play 2004 (index 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023091801, play 1863 (index 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023092402, play 1418 (index 400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023092406, play 4524 (index 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023100111, play 881 (index 600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023100801, play 1365 (index 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023100805, play 2095 (index 800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023100809, play 3216 (index 900)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023101501, play 4087 (index 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023101511, play 3273 (index 1100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023102204, play 3797 (index 1200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023102901, play 2459 (index 1300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023102904, play 1983 (index 1400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023102912, play 639 (index 1500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023110508, play 2994 (index 1600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023111211, play 3734 (index 1700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023111907, play 4083 (index 1800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023112602, play 678 (index 1900)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023121001, play 4266 (index 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023121006, play 3671 (index 2100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023121709, play 84 (index 2200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023122501, play 336 (index 2300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023123108, play 1734 (index 2400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023123114, play 1987 (index 2500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2024010700, play 2608 (index 2600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Saved defender impact for fold 1 with 8801 records\n",
      "\n",
      "============================================================\n",
      "Fold 2/5\n",
      "============================================================\n",
      "  Training: (10515, 750) | Validation: (2617, 750)\n",
      "  ‚ö° Running GridSearchCV...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kniu91/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/kniu91/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/kniu91/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Best CV AUC: -0.4189\n",
      "  ‚úì Best params: {'colsample_bytree': 0.8, 'learning_rate': 0.0075, 'min_child_samples': 20, 'n_estimators': 500, 'num_leaves': 15, 'reg_alpha': 0, 'reg_lambda': 2.0, 'subsample': 0.8}\n",
      "[500]\ttrain's auc: 0.898403\tvalid's auc: 0.864293\n",
      "\n",
      "  üìä Final Metrics:\n",
      "     Train AUC: 0.8984 | BCE: 0.3741\n",
      "     Val   AUC: 0.8643 | BCE: 0.3996\n",
      "‚úì Predicted on 2617 validation plays (real trajectories)\n",
      "  Mean catch prob: 0.689, Std: 0.270\n",
      "\n",
      "üìä Validation Metrics (Real Trajectories):\n",
      "  real_bce: 0.3996\n",
      "  real_auc: 0.8643\n",
      "  real_acc: 0.8292\n",
      "‚úì Predicted on 2617 projected trajectories\n",
      "Processing defender impact for game 2023091004, play 124 (index 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023091011, play 55 (index 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023091012, play 3197 (index 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023091700, play 4189 (index 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023091703, play 306 (index 400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023091708, play 3755 (index 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023091710, play 2822 (index 600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023092800, play 3234 (index 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023101512, play 1155 (index 800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023102202, play 1375 (index 900)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023102600, play 1859 (index 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023102906, play 2577 (index 1100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023110509, play 3083 (index 1200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023111201, play 3974 (index 1300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023111905, play 390 (index 1400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023111908, play 563 (index 1500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023112301, play 543 (index 1600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023112607, play 82 (index 1700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023120302, play 1768 (index 1800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023120400, play 3063 (index 1900)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023121004, play 2611 (index 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023121011, play 1214 (index 2100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023121600, play 1544 (index 2200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023121711, play 2198 (index 2300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023122407, play 3779 (index 2400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023122800, play 3024 (index 2500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2024010702, play 2873 (index 2600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Saved defender impact for fold 2 with 8680 records\n",
      "\n",
      "============================================================\n",
      "Fold 3/5\n",
      "============================================================\n",
      "  Training: (10516, 750) | Validation: (2616, 750)\n",
      "  ‚ö° Running GridSearchCV...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kniu91/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/kniu91/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/kniu91/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Best CV AUC: -0.4130\n",
      "  ‚úì Best params: {'colsample_bytree': 0.8, 'learning_rate': 0.0075, 'min_child_samples': 20, 'n_estimators': 500, 'num_leaves': 15, 'reg_alpha': 0, 'reg_lambda': 2.0, 'subsample': 0.8}\n",
      "[500]\ttrain's auc: 0.900398\tvalid's auc: 0.85699\n",
      "\n",
      "  üìä Final Metrics:\n",
      "     Train AUC: 0.9004 | BCE: 0.3709\n",
      "     Val   AUC: 0.8570 | BCE: 0.4149\n",
      "‚úì Predicted on 2616 validation plays (real trajectories)\n",
      "  Mean catch prob: 0.681, Std: 0.277\n",
      "\n",
      "üìä Validation Metrics (Real Trajectories):\n",
      "  real_bce: 0.4149\n",
      "  real_auc: 0.8570\n",
      "  real_acc: 0.8200\n",
      "‚úì Predicted on 2616 projected trajectories\n",
      "Processing defender impact for game 2023091005, play 159 (index 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023091010, play 4558 (index 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023091712, play 343 (index 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023092409, play 259 (index 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023092500, play 3119 (index 400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023100104, play 1490 (index 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023100108, play 1997 (index 600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023100500, play 1535 (index 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023100800, play 4503 (index 800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023101200, play 3837 (index 900)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023101508, play 1224 (index 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023102208, play 1278 (index 1100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023102907, play 3090 (index 1200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023102910, play 3503 (index 1300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023111204, play 3439 (index 1400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023111600, play 4152 (index 1500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023111910, play 4203 (index 1600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023112300, play 3970 (index 1700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023112606, play 3860 (index 1800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023120305, play 3282 (index 1900)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023120309, play 3427 (index 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023121101, play 3868 (index 2100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023121705, play 853 (index 2200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023122100, play 1032 (index 2300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2024010703, play 624 (index 2400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2024010707, play 1544 (index 2500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2024010713, play 2905 (index 2600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Saved defender impact for fold 3 with 8846 records\n",
      "\n",
      "============================================================\n",
      "Fold 4/5\n",
      "============================================================\n",
      "  Training: (10487, 750) | Validation: (2645, 750)\n",
      "  ‚ö° Running GridSearchCV...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kniu91/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/kniu91/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/kniu91/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Best CV AUC: -0.4134\n",
      "  ‚úì Best params: {'colsample_bytree': 0.8, 'learning_rate': 0.0075, 'min_child_samples': 20, 'n_estimators': 500, 'num_leaves': 15, 'reg_alpha': 0, 'reg_lambda': 2.0, 'subsample': 0.8}\n",
      "[500]\ttrain's auc: 0.898468\tvalid's auc: 0.862719\n",
      "\n",
      "  üìä Final Metrics:\n",
      "     Train AUC: 0.8985 | BCE: 0.3699\n",
      "     Val   AUC: 0.8627 | BCE: 0.4171\n",
      "‚úì Predicted on 2645 validation plays (real trajectories)\n",
      "  Mean catch prob: 0.671, Std: 0.282\n",
      "\n",
      "üìä Validation Metrics (Real Trajectories):\n",
      "  real_bce: 0.4171\n",
      "  real_auc: 0.8627\n",
      "  real_acc: 0.8174\n",
      "‚úì Predicted on 2645 projected trajectories\n",
      "Processing defender impact for game 2023090700, play 101 (index 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023091008, play 396 (index 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023092100, play 498 (index 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023092403, play 1490 (index 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023092412, play 592 (index 400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023092501, play 3569 (index 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023100112, play 55 (index 600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023100802, play 3841 (index 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023101505, play 684 (index 800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023102209, play 480 (index 900)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023102902, play 4298 (index 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023110200, play 2110 (index 1100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023110505, play 1563 (index 1200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023110510, play 99 (index 1300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023110900, play 3921 (index 1400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023111206, play 1952 (index 1500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023111903, play 1129 (index 1600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023112609, play 5183 (index 1700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023120304, play 1700 (index 1800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023120308, play 2594 (index 1900)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023121002, play 2757 (index 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023121009, play 3175 (index 2100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023121702, play 3484 (index 2200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023122410, play 3861 (index 2300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing defender impact for game 2023123000, play 3991 (index 2400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# TRAINING LOOP\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[3/4] Training LightGBM models...\")\n",
    "sequence_ids = realTrajectoryObject.sequence_ids\n",
    "sequences = realTrajectoryObject.sequences\n",
    "\n",
    "groups = np.array([d['game_id'] for d in sequence_ids])\n",
    "gkf = GroupKFold(n_splits=config.N_FOLDS)\n",
    "\n",
    "models, scalers, fold_metrics = [], [], []\n",
    "\n",
    "want_out_fold_metrics = True\n",
    "\n",
    "for fold, (tr, va) in enumerate(gkf.split(sequences, groups=groups), 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Fold {fold}/{config.N_FOLDS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Prepare data splits\n",
    "    X_all = [sequences[i] for i in tr]\n",
    "    y_all = [realTrajectoryObject.targets_catch[i] for i in tr]\n",
    "    X_out = [sequences[i] for i in va]\n",
    "    y_out = [realTrajectoryObject.targets_catch[i] for i in va]\n",
    "    X_traj = [projTrajectoryObject.sequences[i] for i in va]\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(np.vstack([s for s in X_all]))\n",
    "\n",
    "    X_all_sc = [scaler.transform(s) for s in X_all]\n",
    "    X_out_sc = [scaler.transform(s) for s in X_out]\n",
    "    X_traj_sc = [scaler.transform(s) for s in X_traj]\n",
    "\n",
    "    # Train LightGBM with GridSearchCV + early stopping\n",
    "    model, val_auc, val_bce = train_lightgbm_with_tuning(\n",
    "        X_all_sc, y_all, X_out_sc, y_out, config\n",
    "    )\n",
    "\n",
    "    # Predict on REAL trajectories (validation set)\n",
    "    X_out_flat = np.vstack([s.flatten() for s in X_out_sc])\n",
    "    preds_out = model.predict(X_out_flat)\n",
    "    print(f\"‚úì Predicted on {len(preds_out)} validation plays (real trajectories)\")\n",
    "    print(f\"  Mean catch prob: {preds_out.mean():.3f}, Std: {preds_out.std():.3f}\")\n",
    "    \n",
    "    if want_out_fold_metrics:\n",
    "        metrics_real = compute_metrics(np.array(y_out), preds_out, prefix=\"real_\")\n",
    "        print_metrics(metrics_real, title=\"üìä Validation Metrics (Real Trajectories)\")\n",
    "\n",
    "    # Predict on PROJECTED trajectories\n",
    "    X_traj_flat = np.vstack([s.flatten() for s in X_traj_sc])\n",
    "    preds_traj = model.predict(X_traj_flat)\n",
    "    print(f\"‚úì Predicted on {len(preds_traj)} projected trajectories\")\n",
    "\n",
    "    # Save catch probability predictions\n",
    "    game_ids = [projTrajectoryObject.sequence_ids[i]['game_id'] for i in va]\n",
    "    play_ids = [projTrajectoryObject.sequence_ids[i]['play_id'] for i in va]\n",
    "    out_df = pd.DataFrame({'game_id': game_ids,'play_id': play_ids, 'pred_catch_prob_by_proj_traj': preds_traj,'pred_catch_prob_by_real_traj': preds_out})\n",
    "    out_df.to_csv(config.OUTPUT_DIR / 'catch_probabilities_lgb.csv', index=False,  header=(fold == 1),  mode='w' if fold == 1 else 'a') \n",
    "\n",
    "\n",
    "    # ===================\n",
    "    # üî• THE COOL PART: Defender Impact Analysis\n",
    "    # ===================\n",
    "    val_game_ids = [projTrajectoryObject.sequence_ids[i]['game_id'] for i in va]\n",
    "    val_play_ids = [projTrajectoryObject.sequence_ids[i]['play_id'] for i in va]\n",
    "    \n",
    "    all_impacts = []\n",
    "    \n",
    "    for num, (game_id, play_id) in enumerate(zip(val_game_ids, val_play_ids)):\n",
    "        if num % 100 == 0:\n",
    "            print(f\"Processing defender impact for game {game_id}, play {play_id} (index {num})\")\n",
    "        \n",
    "        impact_df = get_defender_impact_flipped(\n",
    "            model, scaler, \n",
    "            projTrajectoryObject.input_df,  # Projected trajectories\n",
    "            realTrajectoryObject.input_df,   # Real trajectories\n",
    "            game_id, play_id, config\n",
    "        )\n",
    "        \n",
    "        if impact_df is not None:\n",
    "            impact_df['game_id'] = game_id\n",
    "            impact_df['play_id'] = play_id\n",
    "            impact_df['fold'] = fold\n",
    "            impact_df = impact_df[['game_id', 'play_id', 'nfl_id', 'player_role', 'baseline_prob', 'real_prob', 'delta', 'fold' ]]\n",
    "            all_impacts.append(impact_df)\n",
    "    \n",
    "    # Save defender impact results\n",
    "    if all_impacts:\n",
    "        fold_impact_df = pd.concat(all_impacts, ignore_index=True)\n",
    "        fold_impact_df.to_csv(config.OUTPUT_DIR / 'defender_impact_lgb.csv', index=False, header=(fold == 1), mode='w' if fold == 1 else 'a'\n",
    "        )\n",
    "        print(f\"‚úì Saved defender impact for fold {fold} with {len(fold_impact_df)} records\")\n",
    "\n",
    "    # Store models and metrics\n",
    "    models.append(model)\n",
    "    scalers.append(scaler)\n",
    "    fold_metrics.append({'fold': fold, 'auc': val_auc, 'bce': val_bce})\n",
    "\n",
    "# ===================\n",
    "# Final Summary\n",
    "# ===================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL CROSS-VALIDATION SUMMARY (LightGBM)\")\n",
    "print(\"=\"*80)\n",
    "fold_df = pd.DataFrame(fold_metrics)\n",
    "print(fold_df.to_string(index=False))\n",
    "print(f\"\\nMean AUC: {fold_df['auc'].mean():.4f} ¬± {fold_df['auc'].std():.4f}\")\n",
    "print(f\"Mean BCE: {fold_df['bce'].mean():.4f} ¬± {fold_df['bce'].std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ecc0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[QUICK TEST] Single train/val split...\n",
      "\n",
      "üü¢ LightGBM:\n",
      "  Training: (10463, 750) | Validation: (2669, 750)\n",
      "  ‚ö° Running GridSearchCV...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Train both models\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# print(\"\\nüîµ Logistic Regression:\")\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# lr_model, lr_cv_score = train_logistic_regression(\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m#     X_train_sc, y_train, X_train[0].shape[-1], config, cv_folds=3\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müü¢ LightGBM:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m lgb_model, lgb_val_auc, lgb_val_bce = \u001b[43mtrain_lightgbm_with_tuning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Compare on held-out validation set\u001b[39;00m\n\u001b[32m     43\u001b[39m X_val_flat = np.vstack([s.flatten() \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m X_val_sc])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mtrain_lightgbm_with_tuning\u001b[39m\u001b[34m(X_train, y_train, X_val, y_val, config)\u001b[39m\n\u001b[32m     40\u001b[39m grid_search = GridSearchCV(\n\u001b[32m     41\u001b[39m     base_model, param_grid, cv=\u001b[32m3\u001b[39m, scoring=\u001b[33m'\u001b[39m\u001b[33mneg_log_loss\u001b[39m\u001b[33m'\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m, verbose=\u001b[32m1\u001b[39m\n\u001b[32m     42\u001b[39m )\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  ‚ö° Running GridSearchCV...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ‚úì Best CV AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search.best_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ‚úì Best params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search.best_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/bdb-26/.venv/lib/python3.13/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# IAM QUICK TEST, DON'T YOU RUN ME!\n",
    "\n",
    "\n",
    "# üî• OPTION 1: Single train/val split (5 minutes)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"\\n[QUICK TEST] Single train/val split...\")\n",
    "\n",
    "# Use game_id for grouping\n",
    "X_all = sequences\n",
    "y_all = realTrajectoryObject.targets_catch\n",
    "groups_all = np.array([d['game_id'] for d in sequence_ids])\n",
    "\n",
    "# 80/20 split\n",
    "unique_games = np.unique(groups_all)\n",
    "train_games, val_games = train_test_split(\n",
    "    unique_games, test_size=0.2, random_state=9\n",
    ")\n",
    "\n",
    "train_mask = np.isin(groups_all, train_games)\n",
    "val_mask = np.isin(groups_all, val_games)\n",
    "\n",
    "X_train = [X_all[i] for i in np.where(train_mask)[0]]\n",
    "y_train = [y_all[i] for i in np.where(train_mask)[0]]\n",
    "X_val = [X_all[i] for i in np.where(val_mask)[0]]\n",
    "y_val = [y_all[i] for i in np.where(val_mask)[0]]\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(np.vstack(X_train))\n",
    "X_train_sc = [scaler.transform(s) for s in X_train]\n",
    "X_val_sc = [scaler.transform(s) for s in X_val]\n",
    "\n",
    "# Train both models\n",
    "# print(\"\\nüîµ Logistic Regression:\")\n",
    "# lr_model, lr_cv_score = train_logistic_regression(\n",
    "#     X_train_sc, y_train, X_train[0].shape[-1], config, cv_folds=3\n",
    "# )\n",
    "\n",
    "print(\"\\nüü¢ LightGBM:\")\n",
    "lgb_model, lgb_val_auc, lgb_val_bce = train_lightgbm_with_tuning(\n",
    "    X_train_sc, y_train, X_val_sc, y_val, config\n",
    ")\n",
    "\n",
    "# Compare on held-out validation set\n",
    "X_val_flat = np.vstack([s.flatten() for s in X_val_sc])\n",
    "y_val_array = np.array(y_val)\n",
    "\n",
    "# lr_preds = lr_model.predict_proba(X_val_flat)[:, 1]\n",
    "lgb_preds = lgb_model.predict(X_val_flat)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üèÜ QUICK COMPARISON (Held-out Validation Set)\")\n",
    "print(\"=\"*60)\n",
    "# print(f\"Logistic Regression:\")\n",
    "# print(f\"  AUC: {roc_auc_score(y_val_array, lr_preds):.4f}\")\n",
    "# print(f\"  BCE: {log_loss(y_val_array, lr_preds):.4f}\")\n",
    "# print(f\"  ACC: {accuracy_score(y_val_array, (lr_preds > 0.5).astype(int)):.4f}\")\n",
    "print(f\"\\nLightGBM:\")\n",
    "print(f\"  AUC: {lgb_val_auc:.4f}\")\n",
    "print(f\"  BCE: {lgb_val_bce:.4f}\")\n",
    "print(f\"  ACC: {accuracy_score(y_val_array, (lgb_preds > 0.5).astype(int)):.4f}\")\n",
    "# print(f\"\\nŒî AUC: {lgb_val_auc - roc_auc_score(y_val_array, lr_preds):+.4f}\")\n",
    "# print(f\"Œî BCE: {lgb_val_bce - log_loss(y_val_array, lr_preds):+.4f}\")\n",
    "# print(f\"Œî ACC: {accuracy_score(y_val_array, (lgb_preds > 0.5).astype(int)) - accuracy_score(y_val_array, (lr_preds > 0.5).astype(int)):+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a411f95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # join all impacts\n",
    "# if all_impacts:\n",
    "#     fold_impact_df = pd.concat(all_impacts, ignore_index=True)\n",
    "#     importancea_dfs.append(fold_impact_df)\n",
    "\n",
    "pd.concat(all_impacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe91377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feature_importance(model, X_val, y_val, feature_names, device, n_repeats=3):\n",
    "    \"\"\"Permutation-based feature importance\"\"\"\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    # model.eval()\n",
    "    X_val_tensor = torch.tensor(np.stack(X_val).astype(np.float32)).to(device)\n",
    "    y_val_array = np.array(y_val)\n",
    "    \n",
    "    # Baseline score\n",
    "    with torch.no_grad():\n",
    "        baseline_pred = torch.sigmoid(model(X_val_tensor)).cpu().numpy()\n",
    "        baseline_score = roc_auc_score(y_val_array, baseline_pred)\n",
    "    \n",
    "    importances = []\n",
    "    \n",
    "    for feat_idx in tqdm(range(len(feature_names)), desc=\"Computing importances\"):\n",
    "        scores = []\n",
    "        for _ in range(n_repeats):\n",
    "            X_permuted = [x.copy() for x in X_val]\n",
    "            # Permute this feature across all sequences\n",
    "            perm_values = np.random.permutation([x[:, feat_idx] for x in X_val])\n",
    "            for i, x in enumerate(X_permuted):\n",
    "                x[:, feat_idx] = perm_values[i]\n",
    "            \n",
    "            X_perm_tensor = torch.tensor(np.stack(X_permuted).astype(np.float32)).to(device)\n",
    "            with torch.no_grad():\n",
    "                perm_pred = torch.sigmoid(model(X_perm_tensor)).cpu().numpy()\n",
    "                perm_score = roc_auc_score(y_val_array, perm_pred)\n",
    "            scores.append(baseline_score - perm_score)  # Drop in performance\n",
    "        \n",
    "        importances.append(np.mean(scores))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    return importance_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[3/4] Training geometric models...\")\n",
    "groups = np.array([d['game_id'] for d in sequence_ids])\n",
    "gkf = GroupKFold(n_splits=config.N_FOLDS)\n",
    "\n",
    "models, scalers = [], []\n",
    "\n",
    "calibration_r2s = []  # ADD THIS BEFORE LOOP\n",
    "importance_dfs = []  # STORE IMPORTANCE DFS\n",
    "\n",
    "for fold, (tr, va) in enumerate(gkf.split(sequences, groups=groups), 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Fold {fold}/{config.N_FOLDS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    X_tr = [sequences[i] for i in tr]\n",
    "    X_va = [sequences[i] for i in va]\n",
    "    y_tr = [targets_catch[i] for i in tr]\n",
    "    y_va = [targets_catch[i] for i in va]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(np.vstack([s for s in X_tr]))\n",
    "\n",
    "    X_tr_sc = [scaler.transform(s) for s in X_tr]\n",
    "    X_va_sc = [scaler.transform(s) for s in X_va]\n",
    "        \n",
    "    model, loss, train_loss, auc, acc, prec, rec, f1, y_pred_proba = train_model(\n",
    "        X_tr_sc, y_tr,\n",
    "        X_va_sc, y_va,\n",
    "        X_tr[0].shape[-1], config = config\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úì Fold {fold} validation outcomes - BCE Loss: {loss:.5f}, Train Loss: {train_loss:.5f}, AUC: {auc:.3f}, Acc: {acc:.3f}, Prec: {prec:.3f}, Rec: {rec:.3f}, F1: {f1:.3f}\")\n",
    "    \n",
    "    # ==================================\n",
    "    # üî• CALIBRATION CHECK\n",
    "    # ==================================\n",
    "    model.eval()\n",
    "    # X_va_tensor = torch.tensor(np.stack(X_va_sc).astype(np.float32)).to(config.DEVICE)\n",
    "    # with torch.no_grad():\n",
    "    #     y_va_pred_proba = torch.sigmoid(model(X_va_tensor)).cpu().numpy()\n",
    "    \n",
    "    # bins = np.linspace(0, 1, 11)\n",
    "    # bin_indices = np.digitize(y_va_pred_proba, bins) - 1\n",
    "    \n",
    "    # predicted_probs, actual_rates = [], []\n",
    "    # for i in range(10):\n",
    "    #     mask = (bin_indices == i)\n",
    "    #     if mask.sum() > 0:\n",
    "    #         predicted_probs.append(y_va_pred_proba[mask].mean())\n",
    "    #         actual_rates.append(np.array(y_va)[mask].mean())\n",
    "    \n",
    "    # from sklearn.metrics import r2_score\n",
    "    # if len(predicted_probs) > 1:\n",
    "    #     r2 = r2_score(actual_rates, predicted_probs)\n",
    "    #     calibration_r2s.append(r2)  # üî• STORE IT\n",
    "    #     print(f\"üìà Calibration R¬≤ = {r2:.3f}\")\n",
    "    # ==================================\n",
    "    # üî• CALIBRATION CHECK\n",
    "    # ==================================\n",
    "    \n",
    "    models.append(model)\n",
    "    scalers.append(scaler)\n",
    "     \n",
    "    # Feature importance code...\n",
    "    print(f\"\\nüìä Computing feature importance for fold {fold}...\")\n",
    "    importance_df = compute_feature_importance(\n",
    "        model, X_va_sc, y_va, feature_cols, config.DEVICE, n_repeats=3\n",
    "    )\n",
    "    importance_dfs.append(importance_df)\n",
    "    \n",
    "# üî• FINAL SUMMARY\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL MODEL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Mean Calibration R¬≤: {np.mean(calibration_r2s):.3f} ¬± {np.std(calibration_r2s):.3f}\")\n",
    "print(f\"üèÜ NFL Benchmark: 0.98 | Your Gap: {0.98 - np.mean(calibration_r2s):.3f}\")\n",
    "\n",
    "all_importances = []\n",
    "for fold in range(1, config.N_FOLDS + 1):\n",
    "    df = importance_dfs[fold-1]\n",
    "    all_importances.append(df)\n",
    "\n",
    "avg_importance = pd.concat(all_importances).groupby('feature')['importance'].mean()\n",
    "avg_importance = avg_importance.sort_values(ascending=False).reset_index()\n",
    "\n",
    "print(avg_importance.head(30))\n",
    "avg_importance.to_csv(config.OUTPUT_DIR / 'feature_importance_avg.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49caec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba71f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "for fold, (tr, va) in enumerate(gkf.split(sequences, groups=groups), 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Fold {fold}/{config.N_FOLDS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    X_tr = [sequences[i] for i in tr]\n",
    "    X_va = [sequences[i] for i in va]\n",
    "    y_tr = [targets_catch[i] for i in tr]\n",
    "    y_va = [targets_catch[i] for i in va]\n",
    "\n",
    "    # Flatten sequences: (num_samples, 10 timesteps, 153 features) -> (num_samples, 1530)\n",
    "    X_tr_flat = np.vstack([s.flatten() for s in X_tr])\n",
    "    X_va_flat = np.vstack([s.flatten() for s in X_va])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_tr_sc = scaler.fit_transform(X_tr_flat)\n",
    "    X_va_sc = scaler.transform(X_va_flat)\n",
    "    \n",
    "    # Grid search for best C (inverse regularization strength)\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],  # L2 penalty strength\n",
    "        'max_iter': [1000]\n",
    "    }\n",
    "    \n",
    "    base_model = LogisticRegression(penalty='l2', solver='lbfgs', random_state=config.SEED)\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        base_model, \n",
    "        param_grid, \n",
    "        cv=3,  # 3-fold CV within training data\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(f\"  Running GridSearchCV...\")\n",
    "    grid_search.fit(X_tr_sc, y_tr)\n",
    "    \n",
    "    print(f\"  Best params: {grid_search.best_params_}\")\n",
    "    print(f\"  Best CV score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Use best model\n",
    "    model = grid_search.best_estimator_\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    y_va_pred_proba = model.predict_proba(X_va_sc)[:, 1]\n",
    "    y_va_pred = (y_va_pred_proba > 0.5).astype(int)\n",
    "    \n",
    "    # üî• ADD BCE COMPUTATION\n",
    "    bce_loss = log_loss(y_va, y_va_pred_proba)\n",
    "    \n",
    "    val_auc = roc_auc_score(y_va, y_va_pred_proba)\n",
    "    acc = accuracy_score(y_va, y_va_pred)\n",
    "    precision = precision_score(y_va, y_va_pred, zero_division=0)\n",
    "    recall = recall_score(y_va, y_va_pred, zero_division=0)\n",
    "    f1 = f1_score(y_va, y_va_pred, zero_division=0)\n",
    "    \n",
    "    # üî• UPDATE PRINT TO INCLUDE BCE\n",
    "    print(f\"  Validation: BCE={bce_loss:.4f}, AUC={val_auc:.4f}, Acc={acc:.3f}, \"\n",
    "          f\"Prec={precision:.3f}, Rec={recall:.3f}, F1={f1:.3f}\")\n",
    "    \n",
    "    models.append(model)\n",
    "    scalers.append(scaler)\n",
    "    \n",
    "    # Feature importance from coefficients\n",
    "    coef = model.coef_[0]  # Shape: (1530,) for flattened features\n",
    "    \n",
    "    # Aggregate across timesteps: (10 timesteps, 153 features) -> (153,)\n",
    "    coef_reshaped = coef.reshape(10, len(feature_cols))\n",
    "    feature_importance = np.abs(coef_reshaped).mean(axis=0)  # Average across time\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': feature_importance\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nüèÜ Top 20 Features:\")\n",
    "    print(importance_df.head(20).to_string(index=False))\n",
    "    \n",
    "    importance_df.to_csv(config.OUTPUT_DIR / f'importance_fold{fold}_logreg.csv', index=False)\n",
    "\n",
    "# After all folds, aggregate\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGGREGATED FEATURE IMPORTANCE ACROSS FOLDS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_importances = []\n",
    "for fold in range(1, config.N_FOLDS + 1):\n",
    "    df = pd.read_csv(config.OUTPUT_DIR / f'importance_fold{fold}_logreg.csv')\n",
    "    all_importances.append(df)\n",
    "\n",
    "avg_importance = pd.concat(all_importances).groupby('feature')['importance'].mean()\n",
    "avg_importance = avg_importance.sort_values(ascending=False).reset_index()\n",
    "print(avg_importance.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c000d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5cf42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON, config\n",
    "    )\n",
    "    \n",
    "    models.append(model)\n",
    "    scalers.append(scaler)\n",
    "    \n",
    "    print(f\"\\n‚úì Fold {fold} - Loss: {loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3ee877",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for fold, (tr, va) in enumerate(gkf.split(sequences, groups=groups), 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Fold {fold}/{config.N_FOLDS}\")\n",
    "    print(f\"{'='*60}\")a\n",
    "    \n",
    "    X_tr = [sequences[i] for i in tr]\n",
    "    X_va = [sequences[i] for i in va]\n",
    "    y_tr_dx = [targets_dx[i] for i in tr]\n",
    "    y_va_dx = [targets_dx[i] for i in va]\n",
    "    y_tr_dy = [targets_dy[i] for i in tr]\n",
    "    y_va_dy = [targets_dy[i] for i in va]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(np.vstack([s for s in X_tr]))\n",
    "    \n",
    "    X_tr_sc = [scaler.transform(s) for s in X_tr]\n",
    "    X_va_sc = [scaler.transform(s) for s in X_va]\n",
    "    \n",
    "    model, loss = train_model(\n",
    "        X_tr_sc, y_tr_dx, y_tr_dy,\n",
    "        X_va_sc, y_va_dx, y_va_dy,\n",
    "        X_tr[0].shape[-1], config.MAX_FUTURE_HORIZON, config\n",
    "    )\n",
    "    \n",
    "    models.append(model)\n",
    "    scalers.append(scaler)\n",
    "    \n",
    "    print(f\"\\n‚úì Fold {fold} - Loss: {loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85efdec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09bc508",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = prepare_sequences_geometric(train_input, train_output, is_training=True, window_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ad55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd919b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Get Opponent Features\n",
    "# ==========================================\n",
    "# This includes mirror / wr tracking\n",
    "# Seems like wecan include because it only has speed and positions?\n",
    "\n",
    "# TODO: Implement opponent features\n",
    "# Hopefully we just need to update some variable names after getting kinematics in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9e5b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Extract route patterns\n",
    "# ==========================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f05a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Compute neighbor embeddings\n",
    "# ==========================================\n",
    "# This is the GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20f497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Create temporal features (rolling mean)\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e85b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Time features\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804ec7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Geometric features\n",
    "# =========================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
